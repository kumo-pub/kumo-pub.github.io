"use strict";(self.webpackChunkkumo_website=self.webpackChunkkumo_website||[]).push([[66011],{84383:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>c,toc:()=>l});var a=t(74848),s=t(28453);const o={},i="\u7528\u6237\u6307\u5357",c={id:"cpp/alkaid/acero/user_guide",title:"\u7528\u6237\u6307\u5357",description:"\u672c\u9875\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 Acero\u3002\u5efa\u8bae\u60a8\u5148\u9605\u8bfb",source:"@site/versioned_docs/version-1.1.1/cpp/alkaid/acero/user_guide.mdx",sourceDirName:"cpp/alkaid/acero",slug:"/cpp/alkaid/acero/user_guide",permalink:"/docs/cpp/alkaid/acero/user_guide",draft:!1,unlisted:!1,tags:[],version:"1.1.1",frontMatter:{},sidebar:"docs",previous:{title:"\u6982\u89c8",permalink:"/docs/cpp/alkaid/acero/overview"},next:{title:"\u5f00\u53d1\u8005\u6307\u5357",permalink:"/docs/cpp/alkaid/acero/developer_guide"}},r={},l=[{value:"\u4f7f\u7528 Acero",id:"\u4f7f\u7528-acero",level:2},{value:"\u521b\u5efa\u8ba1\u5212",id:"\u521b\u5efa\u8ba1\u5212",level:2},{value:"Using Substrait",id:"using-substrait",level:3},{value:"\u7a0b\u5e8f\u5316\u8ba1\u5212\u5236\u5b9a",id:"\u7a0b\u5e8f\u5316\u8ba1\u5212\u5236\u5b9a",level:3},{value:"\u6267\u884c\u8ba1\u5212",id:"\u6267\u884c\u8ba1\u5212",level:3},{value:"DeclarationToTable",id:"declarationtotable",level:3},{value:"DeclarationToReader",id:"declarationtoreader",level:3},{value:"DeclarationToStatus",id:"declarationtostatus",level:3},{value:"Running a Plan Directly",id:"running-a-plan-directly",level:3},{value:"\u63d0\u4f9b\u8f93\u5165",id:"\u63d0\u4f9b\u8f93\u5165",level:2},{value:"\u53ef\u7528\u7684 <code>ExecNode</code> \u5b9e\u73b0",id:"\u53ef\u7528\u7684-execnode-\u5b9e\u73b0",level:2},{value:"\u6e90\u8282\u70b9 -- Sources Nodes",id:"\u6e90\u8282\u70b9----sources-nodes",level:3},{value:"\u8ba1\u7b97\u8282\u70b9 -- Compute Nodes",id:"\u8ba1\u7b97\u8282\u70b9----compute-nodes",level:3},{value:"\u6392\u5217\u8282\u70b9 -- Arrangement Nodes",id:"\u6392\u5217\u8282\u70b9----arrangement-nodes",level:3},{value:"\u6c47\u805a\u8282\u70b9 -- Sink Nodes",id:"\u6c47\u805a\u8282\u70b9----sink-nodes",level:3},{value:"\u793a\u4f8b",id:"\u793a\u4f8b",level:2},{value:"<code>\u6e90</code> <code>source</code>",id:"\u6e90-source",level:3},{value:"<code>table_source</code>",id:"table_source",level:3},{value:"<code>filter</code>",id:"filter",level:3},{value:"<code>project</code>",id:"project",level:3},{value:"<code>aggregate</code>",id:"aggregate",level:3},{value:"<code>sink</code>",id:"sink",level:3},{value:"<code>consuming_sink</code>",id:"consuming_sink",level:3},{value:"<code>order_by_sink</code>",id:"order_by_sink",level:3},{value:"<code>select_k_sink</code>",id:"select_k_sink",level:3},{value:"<code>table_sink</code>",id:"table_sink",level:3},{value:"<code>scan</code>",id:"scan",level:3},{value:"<code>write</code>",id:"write",level:3},{value:"<code>union</code>",id:"union",level:3},{value:"<code>hash_join</code>",id:"hash_join",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",div:"div",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"\u7528\u6237\u6307\u5357",children:"\u7528\u6237\u6307\u5357"})}),"\n",(0,a.jsx)(n.p,{children:"\u672c\u9875\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528 Acero\u3002\u5efa\u8bae\u60a8\u5148\u9605\u8bfb\n\u6982\u8ff0\u5e76\u719f\u6089\u57fa\u672c\u6982\u5ff5\u3002"}),"\n",(0,a.jsx)(n.h2,{id:"\u4f7f\u7528-acero",children:"\u4f7f\u7528 Acero"}),"\n",(0,a.jsx)(n.p,{children:"Acero \u7684\u57fa\u672c\u5de5\u4f5c\u6d41\u7a0b\u5982\u4e0b\uff1a"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\u9996\u5148\uff0c\u521b\u5efa\u4e00\u4e2a\u63cf\u8ff0\u8ba1\u5212\u7684\u201cDeclaration\u201d\u5bf9\u8c61\u56fe"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\u8c03\u7528\u5176\u4e2d\u4e00\u4e2aDeclarationToXyz \u65b9\u6cd5\u6267\u884c\u58f0\u660e\u3002"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\u4ece\u58f0\u660e\u56fe\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 ExecPlan\u3002\u6bcf\u4e2a\nDeclaration \u5c06\u5bf9\u5e94\u8ba1\u5212\u4e2d\u7684\u4e00\u4e2a ExecNode\u3002\n\u6b64\u5916\uff0c\u5c06\u6dfb\u52a0\u4e00\u4e2a\u63a5\u6536\u5668\u8282\u70b9\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u4f7f\u7528\u4e86\u54ea\u4e2a\nDeclarationToXyz \u65b9\u6cd5\u3002"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\u6267\u884c ExecPlan\u3002\u901a\u5e38\uff0c\u8fd9\u662f\u4f5c\u4e3a\nDeclarationToXyz \u8c03\u7528\u7684\u4e00\u90e8\u5206\u53d1\u751f\u7684\uff0c\u4f46\u5728DeclarationToReader \u4e2d\uff0c\u8bfb\u53d6\u5668\u5728\u8ba1\u5212\u6267\u884c\u5b8c\u6210\u4e4b\u524d\u8fd4\u56de\u3002"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\u8ba1\u5212\u5b8c\u6210\u540e\uff0c\u5b83\u5c06\u88ab\u9500\u6bc1"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"\u521b\u5efa\u8ba1\u5212",children:"\u521b\u5efa\u8ba1\u5212"}),"\n",(0,a.jsx)(n.h3,{id:"using-substrait",children:"Using Substrait"}),"\n",(0,a.jsxs)(n.p,{children:["Substrait \u662f\u521b\u5efa\u8ba1\u5212\uff08",(0,a.jsx)(n.code,{children:"Declaration"})," \u56fe\uff09\u7684\u9996\u9009\u673a\u5236\u3002\u539f\u56e0\u5982\u4e0b\uff1a"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Substrait \u751f\u4ea7\u8005\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u548c\u7cbe\u529b\u521b\u5efa\u7528\u6237\u53cb\u597d\u7684 API\uff0c\u4ee5\u4fbf\u4ee5\u7b80\u5355\u7684\u65b9\u5f0f\u751f\u6210\u590d\u6742\u7684\u6267\u884c\u8ba1\u5212\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e00\u7cfb\u5217\u590d\u6742\u7684 ",(0,a.jsx)(n.code,{children:"aggregate"})," \u8282\u70b9\u6765\n\u5b9e\u73b0 ",(0,a.jsx)(n.code,{children:"pivot_wider"})," \u64cd\u4f5c\u3002\u751f\u4ea7\u8005\u5c06\u4e3a\u60a8\u63d0\u4f9b\u66f4\u7b80\u5355\u7684 API\uff0c\u800c\u4e0d\u662f\u624b\u52a8\u521b\u5efa\u6240\u6709\u8fd9\u4e9b ",(0,a.jsx)(n.code,{children:"aggregate"})," \u8282\u70b9\u3002"]}),"\n",(0,a.jsx)(n.li,{children:"\u5982\u679c\u60a8\u6b63\u5728\u4f7f\u7528 Substrait\uff0c\u90a3\u4e48\u5982\u679c\u60a8\u5728\u67d0\u4e2a\u65f6\u5019\u53d1\u73b0\u5b83\u6bd4 Acero \u66f4\u80fd\u6ee1\u8db3\u60a8\u7684\u9700\u6c42\uff0c\u60a8\u53ef\u4ee5\u8f7b\u677e\u5207\u6362\u5230\u4efb\u4f55\u5176\u4ed6\u4f7f\u7528 Substrait \u7684\u5f15\u64ce\u3002"}),"\n",(0,a.jsx)(n.li,{children:"\u6211\u4eec\u5e0c\u671b\u6700\u7ec8\u4f1a\u51fa\u73b0\u57fa\u4e8e Substrait \u7684\u4f18\u5316\u5668\u548c\u89c4\u5212\u5668\u7684\u5de5\u5177\u3002\u901a\u8fc7\u4f7f\u7528 Substrait\uff0c\u60a8\u5c06\u6765\u53ef\u4ee5\u66f4\u8f7b\u677e\u5730\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u3002"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["\u60a8\u53ef\u4ee5\u81ea\u5df1\u521b\u5efa Substrait \u8ba1\u5212\uff0c\u4f46\u627e\u5230\u73b0\u6709\u7684 Substrait \u751f\u4ea7\u8005\u53ef\u80fd\u4f1a\u66f4\u5bb9\u6613\u3002\u4f8b\u5982\uff0c\n\u60a8\u53ef\u4ee5\u4f7f\u7528\n",(0,a.jsx)(n.a,{href:"https://github.com/ibis-project/ibis-substrait",children:"ibis-substrait"}),"\n\u8f7b\u677e\u5730\u4ece Python \u8868\u8fbe\u5f0f\u521b\u5efa Substrait \u8ba1\u5212\u3002\u6709\u51e0\u79cd\n\u4e0d\u540c\u7684\u5de5\u5177\u80fd\u591f\u4ece SQL \u521b\u5efa Substrait \u8ba1\u5212\u3002\n\u6700\u7ec8\uff0c\u6211\u4eec\u5e0c\u671b\u57fa\u4e8e C++ \u7684 Substrait \u751f\u6210\u5668\u80fd\u591f\u51fa\u73b0\u3002\n\u4f46\u662f\uff0c\u6211\u4eec\u76ee\u524d\u8fd8\u4e0d\u77e5\u9053\u6709\u4efb\u4f55\u8fd9\u6837\u7684\u751f\u6210\u5668\u3002\n\u6709\u5173\u4ece Substrait \u521b\u5efa\u6267\u884c\u8ba1\u5212\u7684\u8be6\u7ec6\u8bf4\u660e\uff0c\n\u53ef\u4ee5\u5728",(0,a.jsx)(n.code,{children:"Substrait \u9875\u9762<acero-substrait>"}),"\u4e2d\u627e\u5230"]}),"\n",(0,a.jsx)(n.h3,{id:"\u7a0b\u5e8f\u5316\u8ba1\u5212\u5236\u5b9a",children:"\u7a0b\u5e8f\u5316\u8ba1\u5212\u5236\u5b9a"}),"\n",(0,a.jsx)(n.p,{children:"\u901a\u8fc7\u7f16\u7a0b\u65b9\u5f0f\u521b\u5efa\u6267\u884c\u8ba1\u5212\u6bd4\u4ece Substrait \u521b\u5efa\u8ba1\u5212\u66f4\u7b80\u5355\uff0c\u4f46\u4f1a\u5931\u53bb\u4e00\u4e9b\u7075\u6d3b\u6027\u548c\u9762\u5411\u672a\u6765\u7684\u4fdd\u8bc1\u3002\u521b\u5efa\u58f0\u660e\u7684\n\u6700\u7b80\u5355\u65b9\u6cd5\u662f\u7b80\u5355\u5730\u5b9e\u4f8b\u5316\u4e00\u4e2a\u3002\u60a8\u5c06\u9700\u8981\u58f0\u660e\u7684\u540d\u79f0\u3001\u8f93\u5165\u5411\u91cf\u548c\u9009\u9879\u5bf9\u8c61\u3002\u4f8b\u5982\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a project node\n///\n/// Scan-Project-Table\n/// This example shows how a Scan operation can be used to load the data\n/// into the execution plan, how a project operation can be applied on the\n/// data stream and how the output is collected into a table\nturbo::Status ScanProjectSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // projection\n  cp::Expression a_times_2 = cp::call("multiply", {cp::field_ref("a"), cp::literal(2)});\n  options->projection = cp::project({}, {});\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n  ac::Declaration project{\n      "project", {std::move(scan)}, ac::ProjectNodeOptions({a_times_2})};\n\n  return ExecutePlanAndCollectAsTable(std::move(project));\n}\n'})}),"\n",(0,a.jsxs)(n.p,{children:["\u4e0a\u8ff0\u4ee3\u7801\u521b\u5efa\u4e86\u4e00\u4e2a\u626b\u63cf\u58f0\u660e\uff08\u6ca1\u6709\u8f93\u5165\uff09\u548c\u4e00\u4e2a\u9879\u76ee\u58f0\u660e\uff08\u4f7f\u7528\u626b\u63cf\u4f5c\u4e3a\u8f93\u5165\uff09\u3002\u8fd9\u5f88\u7b80\u5355\uff0c\u4f46\u6211\u4eec\u53ef\u4ee5\u8ba9\u5b83\u7a0d\u5fae\u7b80\u5355\u4e00\n\u4e9b\u3002\u5982\u679c\u60a8\u8981\u521b\u5efa\u4e00\u4e2a\u7ebf\u6027\u58f0\u660e\u5e8f\u5217\uff08\u5982\u4e0a\u4f8b\u6240\u793a\uff09\uff0c\u90a3\u4e48\u60a8\u4e5f\u53ef\u4ee5\u4f7f\u7528",(0,a.jsx)(n.code,{children:"Declaration::Sequence"}),"\u51fd\u6570\u3002"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'  // Inputs do not have to be passed to the project node when using Sequence\n  ac::Declaration plan =\n      ac::Declaration::Sequence({{"scan", std::move(scan_node_options)},\n                                 {"project", ac::ProjectNodeOptions({a_times_2})}});\n'})}),"\n",(0,a.jsx)(n.p,{children:"\u672c\u6587\u6863\u540e\u9762\u8fd8\u4f1a\u63d0\u4f9b\u66f4\u591a\u6709\u5173\u7a0b\u5e8f\u5316\u8ba1\u5212\u521b\u5efa\u7684\u793a\u4f8b\u3002"}),"\n",(0,a.jsx)(n.h3,{id:"\u6267\u884c\u8ba1\u5212",children:"\u6267\u884c\u8ba1\u5212"}),"\n",(0,a.jsxs)(n.p,{children:["\u6709\u591a\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\u53ef\u7528\u4e8e\u6267\u884c\n\u58f0\u660e\u3002\u6bcf\u79cd\u65b9\u6cd5\u63d0\u4f9b\u7684\u6570\u636e\u5f62\u5f0f\u7565\u6709\u4e0d\u540c\u3002\n\u7531\u4e8e\u6240\u6709\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u4ee5",(0,a.jsx)(n.code,{children:"DeclarationTo..."}),"\u5f00\u5934\uff0c\u56e0\u6b64\u672c\u6307\u5357\n\u901a\u5e38\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u79f0\u4e3a",(0,a.jsx)(n.code,{children:"DeclarationToXyz"}),"\u65b9\u6cd5\u3002"]}),"\n",(0,a.jsx)(n.h3,{id:"declarationtotable",children:"DeclarationToTable"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"DeclarationToTable"})," \u65b9\u6cd5\u4f1a\u5c06\u6240\u6709\u7ed3\u679c\u7d2f\u79ef\u5230\u5355\u4e2a ",(0,a.jsx)(n.code,{children:"alkaid::Table"})," \u4e2d\u3002\u8fd9\u4e5f\u8bb8\u662f\u4ece Acero\n\u6536\u96c6\u7ed3\u679c\u7684\u6700\u7b80\u5355\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u4e3b\u8981\u7f3a\u70b9\u662f\u5b83\u9700\u8981\u5c06\u6240\u6709\u7ed3\u679c\u7d2f\u79ef\u5230\u5185\u5b58\u4e2d\u3002"]}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsx)(n.p,{children:"Acero \u4ee5\u5c0f\u5757\u7684\u5f62\u5f0f\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u3002\u5f00\u53d1\u4eba\u5458\u6307\u5357\u4e2d\u5bf9\u6b64\u8fdb\u884c\u4e86\u66f4\u8be6\u7ec6\u7684\u63cf\u8ff0\u3002\u56e0\u6b64\uff0c\u60a8\u53ef\u80fd\u4f1a\u60ca\u8bb6\u5730\u53d1\u73b0\u4f7f\u7528 StatementToTable \u6536\u96c6\u7684\u8868\u7684\u5206\u5757\u65b9\u5f0f\u4e0e\u60a8\u7684\u8f93\u5165\n\u4e0d\u540c\u3002\u4f8b\u5982\uff0c\u60a8\u7684\u8f93\u5165\u53ef\u80fd\u662f\u4e00\u4e2a\u5927\u578b\u8868\uff0c\u5176\u4e2d\u5355\u4e2a\u5757\u5305\u542b 200 \u4e07\u884c\u3002\u7136\u540e\uff0c\u60a8\u7684\u8f93\u51fa\u8868\u53ef\u80fd\u6709 64 \u4e2a\u5757\uff0c\u6bcf\u4e2a\u5757\u6709 32Ki \u884c\u3002"})}),"\n",(0,a.jsx)(n.h3,{id:"declarationtoreader",children:"DeclarationToReader"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"DeclarationToReader"})," \u65b9\u6cd5\u5141\u8bb8\u60a8\u8fed\u4ee3\u5730\u4f7f\u7528\n\u7ed3\u679c\u3002\u5b83\u5c06\u521b\u5efa\u4e00\u4e2a ",(0,a.jsx)(n.code,{children:"alkaid::RecordBatchReader"}),"\uff0c\u60a8\u53ef\u4ee5\u5728\u95f2\u6687\u65f6\u4ece\u4e2d\u8bfb\u53d6\u3002\u5982\u679c\u60a8\u6ca1\u6709\u8db3\u591f\u5feb\u5730\u4ece\u8bfb\u53d6\u5668\u8bfb\u53d6\uff0c\u5219\u5c06\u65bd\u52a0\u80cc\u538b\uff0c\u6267\u884c\u8ba1\u5212\u5c06\u6682\u505c\u3002\n\u5173\u95ed\u8bfb\u53d6\u5668\u5c06\u53d6\u6d88\u6b63\u5728\u8fd0\u884c\u7684\u6267\u884c\u8ba1\u5212\uff0c\u8bfb\u53d6\u5668\u7684\u6790\u6784\u51fd\u6570\u5c06\u7b49\u5f85\u6267\u884c\u8ba1\u5212\u5b8c\u6210\u5b83\u6b63\u5728\u6267\u884c\u7684\u4efb\u4f55\u64cd\u4f5c\uff0c\u56e0\u6b64\u5b83\u53ef\u80fd\u4f1a\u963b\u585e\u3002"]}),"\n",(0,a.jsx)(n.h3,{id:"declarationtostatus",children:"DeclarationToStatus"}),"\n",(0,a.jsxs)(n.p,{children:["\u5982\u679c\u60a8\u60f3\u8981\u8fd0\u884c\u8be5\u8ba1\u5212\u4f46\u5b9e\u9645\u4e0a\u5e76\u4e0d\u60f3\u4f7f\u7528\u7ed3\u679c\uff0c\u5219 ",(0,a.jsx)(n.code,{children:"DeclarationToStatus"})," \u65b9\u6cd5\u5f88\u6709\u7528\u3002\u4f8b\u5982\uff0c\u5728\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u6216\u8ba1\u5212\u5177\n\u6709\u526f\u4f5c\u7528\uff08\u4f8b\u5982\u6570\u636e\u96c6\u5199\u5165\u8282\u70b9\uff09\u65f6\uff0c\u8fd9\u5f88\u6709\u7528\u3002\u5982\u679c\u8ba1\u5212\u751f\u6210\u4efb\u4f55\u7ed3\u679c\uff0c\u5219\u8fd9\u4e9b\u7ed3\u679c\u5c06\u88ab\u7acb\u5373\u4e22\u5f03\u3002"]}),"\n",(0,a.jsx)(n.h3,{id:"running-a-plan-directly",children:"Running a Plan Directly"}),"\n",(0,a.jsxs)(n.p,{children:["\u5982\u679c\u51fa\u4e8e\u67d0\u79cd\u539f\u56e0\uff0c",(0,a.jsx)(n.code,{children:"DeclarationToXyz"})," \u65b9\u6cd5\u4e4b\u4e00\u4e0d\u591f\u7528\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c\u8ba1\u5212\u3002\u53ea\u6709\u5728\u6267\u884c\u67d0\u4e9b\u72ec\u7279\n\u64cd\u4f5c\u65f6\u624d\u9700\u8981\u8fd9\u6837\u505a\u3002\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u521b\u5efa\u4e86\u81ea\u5b9a\u4e49\u63a5\u6536\u5668\u8282\u70b9\uff0c\u6216\u8005\u60a8\u9700\u8981\u5177\u6709\u591a\u4e2a\u8f93\u51fa\u7684\u8ba1\u5212\u3002"]}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsx)(n.p,{children:"\u5728\u5b66\u672f\u6587\u732e\u548c\u8bb8\u591a\u73b0\u6709\u7cfb\u7edf\u4e2d\uff0c\u666e\u904d\u5047\u8bbe\u6267\u884c\u8ba1\u5212\u6700\u591a\u53ea\u6709\u4e00\u4e2a\u8f93\u51fa\u3002Acero \u4e2d\u7684\u67d0\n\u4e9b\u65b9\u6cd5\uff08\u4f8b\u5982 StatementToXyz \u65b9\u6cd5\uff09\u4f1a\u671f\u671b\u8fd9\u4e00\u70b9\u3002\u4f46\u662f\uff0c\u8bbe\u8ba1\u4e2d\u6ca1\u6709\u4efb\u4f55\u5185\u5bb9\u4e25\u683c\u963b\u6b62\u6709\u591a\u4e2a\u63a5\u6536\u5668\u8282\u70b9\u3002"})}),"\n",(0,a.jsx)(n.p,{children:"\u6709\u5173\u5982\u4f55\u6267\u884c\u6b64\u64cd\u4f5c\u7684\u8be6\u7ec6\u8bf4\u660e\u8d85\u51fa\u4e86\u672c\u6307\u5357\u7684\u8303\u56f4\n\u4f46\u5927\u81f4\u6b65\u9aa4\u5982\u4e0b\uff1a"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 ",(0,a.jsx)(n.code,{children:"ExecPlan"})," \u5bf9\u8c61\u3002"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["\u5c06\u63a5\u6536\u5668\u8282\u70b9\u6dfb\u52a0\u5230 ",(0,a.jsx)(n.code,{children:"Declaration"})," \u5bf9\u8c61\u56fe\uff08\u8fd9\u662f\n\u521b\u5efa\u63a5\u6536\u5668\u8282\u70b9\u58f0\u660e\u6240\u9700\u7684\u552f\u4e00\u7c7b\u578b\uff09"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"Declaration::AddToPlan"})," \u5c06\u58f0\u660e\u6dfb\u52a0\u5230\u8ba1\u5212\n\uff08\u5982\u679c\u60a8\u6709\u591a\u4e2a\u8f93\u51fa\uff0c\u5219\u60a8\u5c06\u65e0\u6cd5\u4f7f\u7528\n\u6b64\u65b9\u6cd5\uff0c\u5e76\u4e14\u9700\u8981\u4e00\u6b21\u6dfb\u52a0\u4e00\u4e2a\u8282\u70b9\uff09"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"ExecPlan::Validate"})," \u9a8c\u8bc1\u8ba1\u5212"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"ExecPlan::StartProducing"})," \u542f\u52a8\u8ba1\u5212"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["\u7b49\u5f85 ",(0,a.jsx)(n.code,{children:"ExecPlan::finished"})," \u8fd4\u56de\u7684\u672a\u6765\u5b8c\u6210\u3002"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"\u63d0\u4f9b\u8f93\u5165",children:"\u63d0\u4f9b\u8f93\u5165"}),"\n",(0,a.jsx)(n.p,{children:"\u6267\u884c\u8ba1\u5212\u7684\u8f93\u5165\u6570\u636e\u53ef\u4ee5\u6765\u81ea\u5404\u79cd\u6765\u6e90\u3002\u5b83\u901a\u5e38\u662f\u4ece\u5b58\u50a8\u5728\u67d0\u79cd\u6587\u4ef6\u7cfb\u7edf\u4e0a\u7684\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u3002\u8f93\u5165\u901a\u5e38\u6765\u81ea\u5185\u5b58\u6570\u636e\u3002\u4f8b\n\u5982\uff0c\u5728\u7c7b\u4f3c pandas \u7684\u524d\u7aef\u4e2d\uff0c\u5185\u5b58\u6570\u636e\u5f88\u5e38\u89c1\u3002\u8f93\u5165\u4e5f\u53ef\u4ee5\u6765\u81ea\u7f51\u7edc\u6d41\uff0c\u5982\u822a\u73ed\u8bf7\u6c42\u3002Acero \u53ef\u4ee5\u652f\u6301\u6240\u6709\u8fd9\u4e9b\u60c5\u51b5\uff0c\u751a\n\u81f3\u53ef\u4ee5\u652f\u6301\u6b64\u5904\u672a\u63d0\u53ca\u7684\u72ec\u7279\u548c\u81ea\u5b9a\u4e49\u60c5\u51b5\u3002"}),"\n",(0,a.jsxs)(n.p,{children:["\u6709\u9884\u5b9a\u4e49\u7684\u6e90\u8282\u70b9\u6db5\u76d6\u6700\u5e38\u89c1\u7684\u8f93\u5165\u573a\u666f\u3002\u8fd9\u4e9b\u5217\u5728\u4e0b\u9762\u3002\u4f46\u662f\uff0c\u5982\u679c\u60a8\u7684\u6e90\u6570\u636e\u662f\u552f\u4e00\u7684\uff0c\u90a3\u4e48\u60a8\u5c06\u9700\u8981\u4f7f\u7528\u901a\u7528\u7684",(0,a.jsx)(n.code,{children:"\u6e90"}),"\u8282\u70b9\u3002\n\u6b64\u8282\u70b9\u5e0c\u671b\u60a8\u63d0\u4f9b\u5f02\u6b65\u6279\u5904\u7406\u6d41\uff0c\u5e76\u5728",(0,a.jsx)(n.code,{children:"\u6b64\u5904 <stream_execution_source_docs>"}),"\u4e2d\u6709\u66f4\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002"]}),"\n",(0,a.jsxs)(n.h2,{id:"\u53ef\u7528\u7684-execnode-\u5b9e\u73b0",children:["\u53ef\u7528\u7684 ",(0,a.jsx)(n.code,{children:"ExecNode"})," \u5b9e\u73b0"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.p,{children:"\u4e0b\u8868\u5feb\u901f\u603b\u7ed3\u4e86\u53ef\u7528\u7684\u8fd0\u7b97\u7b26\u3002"}),"\n",(0,a.jsx)(n.h3,{id:"\u6e90\u8282\u70b9----sources-nodes",children:"\u6e90\u8282\u70b9 -- Sources Nodes"}),"\n",(0,a.jsx)(n.p,{children:"\u8fd9\u4e9b\u8282\u70b9\u53ef\u4ee5\u4f5c\u4e3a\u6570\u636e\u6e90"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Factory Name"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Options"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Brief Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"source"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"SourceNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["A generic source node that wraps an asynchronous stream of data (",(0,a.jsx)(n.code,{children:"example <stream_execution_source_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"table_source"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TableSourceNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Generates data from an",(0,a.jsx)(n.code,{children:"alkaid::Table"})," (",(0,a.jsx)(n.code,{children:"example <stream_execution_table_source_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"record_batch_source"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"RecordBatchSourceNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Generates data from an iterator of ",(0,a.jsx)(n.code,{children:"alkaid::RecordBatch"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"record_batch_reader_source"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"RecordBatchReaderSourceNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Generates data from an",(0,a.jsx)(n.code,{children:"alkaid::RecordBatchReader"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"exec_batch_source"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"ExecBatchSourceNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Generates data from an iterator of ",(0,a.jsx)(n.code,{children:"alkaid::compute::ExecBatch"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"array_vector_source"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"ArrayVectorSourceNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Generates data from an iterator of vectors of ",(0,a.jsx)(n.code,{children:"alkaid::Array"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"scan"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"alkaid::dataset::ScanNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Generates data from an ",(0,a.jsx)(n.code,{children:"alkaid::dataset::Dataset"})," (requires the datasets module)(",(0,a.jsx)(n.code,{children:"example <stream_execution_scan_docs>"}),")"]})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"\u8ba1\u7b97\u8282\u70b9----compute-nodes",children:"\u8ba1\u7b97\u8282\u70b9 -- Compute Nodes"}),"\n",(0,a.jsx)(n.p,{children:"\u8fd9\u4e9b\u8282\u70b9\u5bf9\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\uff0c\u5e76\u53ef\u80fd\u8f6c\u6362\u6216\u91cd\u5851\u6570\u636e"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Factory Name"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Options"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Brief Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"filter"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"FilterNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Removes rows that do not match a given filter expression(",(0,a.jsx)(n.code,{children:"example <stream_execution_filter_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"project"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"ProjectNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Creates new columns by evaluating compute expressions.  Can also drop and reorder columns(",(0,a.jsx)(n.code,{children:"example <stream_execution_project_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"aggregate"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"AggregateNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Calculates summary statistics across the entire input stream or on groups of data(",(0,a.jsx)(n.code,{children:"example <stream_execution_aggregate_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"pivot_longer"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"PivotLongerNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Reshapes data by converting some columns into additional rows"})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"\u6392\u5217\u8282\u70b9----arrangement-nodes",children:"\u6392\u5217\u8282\u70b9 -- Arrangement Nodes"}),"\n",(0,a.jsx)(n.p,{children:"\u8fd9\u4e9b\u8282\u70b9\u5bf9\u6570\u636e\u6d41\u8fdb\u884c\u91cd\u65b0\u6392\u5e8f\u3001\u7ec4\u5408\u6216\u5207\u7247"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Factory Name"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Options"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Brief Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"hash_join"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"HashJoinNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Joins two inputs based on common columns (:ref:",(0,a.jsx)(n.code,{children:"example <stream_execution_hashjoin_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"asofjoin"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"AsofJoinNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Joins multiple inputs to the first input based on a common ordered column (often time)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"union"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"N/A"}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Merges two inputs with identical schemas (:ref:",(0,a.jsx)(n.code,{children:"example <stream_execution_union_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"order_by"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"OrderByNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Reorders a stream"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"fetch"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"FetchNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Slices a range of rows from a stream"})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"\u6c47\u805a\u8282\u70b9----sink-nodes",children:"\u6c47\u805a\u8282\u70b9 -- Sink Nodes"}),"\n",(0,a.jsx)(n.p,{children:"\u8fd9\u4e9b\u8282\u70b9\u7ec8\u6b62\u8ba1\u5212\u3002\u7528\u6237\u901a\u5e38\u4e0d\u4f1a\u521b\u5efa\u63a5\u6536\u8282\u70b9\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u6839\u636e\u7528\u4e8e\u6d88\u8d39\u8ba1\u5212\u7684DeclarationToXyz\u65b9\u6cd5\u9009\u62e9\u7684\u3002\u4f46\n\u662f\uff0c\u5bf9\u4e8e\u90a3\u4e9b\u5f00\u53d1\u65b0\u63a5\u6536\u8282\u70b9\u6216\u4ee5\u9ad8\u7ea7\u65b9\u5f0f\u4f7f\u7528Acero\u7684\u4eba\u6765\u8bf4\uff0c\u6b64\u5217\u8868\u53ef\u80fd\u5f88\u6709\u7528\u3002"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Factory Name"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Options"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Brief Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"sink"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"SinkNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Collects batches into a FIFO queue with optional backpressure"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"write"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"alkaid::dataset::WriteNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Writes batches to a filesystem (:ref:",(0,a.jsx)(n.code,{children:"example <stream_execution_write_docs>"}),")"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"consuming_sink"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"ConsumingSinkNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Consumes batches using a user provided callback function"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"table_sink"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TableSinkNodeOptions"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Collects batches into an :class:",(0,a.jsx)(n.code,{children:"alkaid::Table"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"order_by_sink"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"OrderBySinkNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Deprecated"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"select_k_sink"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"SelectKSinkNodeOptions"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Deprecated"})]})]})]}),"\n",(0,a.jsx)(n.h2,{id:"\u793a\u4f8b",children:"\u793a\u4f8b"}),"\n",(0,a.jsx)(n.p,{children:"\u672c\u6587\u6863\u7684\u5176\u4f59\u90e8\u5206\u5305\u542b\u793a\u4f8b\u6267\u884c\u8ba1\u5212\u3002\u6bcf\u4e2a\u793a\u4f8b\n\u90fd\u91cd\u70b9\u4ecb\u7ecd\u4e86\u7279\u5b9a\u6267\u884c\u8282\u70b9\u7684\u884c\u4e3a\u3002"}),"\n",(0,a.jsxs)(n.h3,{id:"\u6e90-source",children:[(0,a.jsx)(n.code,{children:"\u6e90"})," ",(0,a.jsx)(n.code,{children:"source"})]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"source"})," \u64cd\u4f5c\u53ef\u89c6\u4e3a\u521b\u5efa\u6d41\u5f0f\u6267\u884c\u8ba1\u5212\u7684\u5165\u53e3\u70b9\u3002",(0,a.jsx)(n.code,{children:"SourceNodeOptions"})," \u7528\u4e8e\u521b\u5efa ",(0,a.jsx)(n.code,{children:"source"})," \u64cd\u4f5c\u3002",(0,a.jsx)(n.code,{children:"source"})," \u64cd\u4f5c\u662f\u76ee\u524d\n\u6700\u901a\u7528\u3001\u6700\u7075\u6d3b\u7684\u6e90\u7c7b\u578b\uff0c\u4f46\u914d\u7f6e\u8d77\u6765\u53ef\u80fd\u76f8\u5f53\u68d8\u624b\u3002\u9996\u5148\uff0c\u60a8\u5e94\u8be5\u67e5\u770b\u5176\u4ed6\u6e90\u8282\u70b9\u7c7b\u578b\uff0c\u4ee5\u786e\u4fdd\u6ca1\u6709\u66f4\u7b80\u5355\u7684\u9009\u62e9\u3002"]}),"\n",(0,a.jsxs)(n.p,{children:["\u6e90\u8282\u70b9\u9700\u8981\u67d0\u79cd\u53ef\u4ee5\u8c03\u7528\u6765\u8f6e\u8be2\u66f4\u591a\u6570\u636e\u7684\u51fd\u6570\u3002\u6b64\u51fd\u6570\u4e0d\u5e94\u5e26\u4efb\u4f55\u53c2\u6570\uff0c\u5e76\u4e14\u5e94\u8fd4\u56de ",(0,a.jsx)(n.code,{children:"alkaid::Future<std::optional<alkaid::ExecBatch>>"}),"\u3002\u6b64\n\u51fd\u6570\u53ef\u80fd\u6b63\u5728\u8bfb\u53d6\u6587\u4ef6\u3001\u904d\u5386\u5185\u5b58\u7ed3\u6784\u6216\u4ece\u7f51\u7edc\u8fde\u63a5\u63a5\u6536\u6570\u636e\u3002alkaid \u5e93\u5c06\u8fd9\u4e9b\u51fd\u6570\u79f0\u4e3a ",(0,a.jsx)(n.code,{children:"alkaid::AsyncGenerator"}),"\uff0c\u5e76\u4e14\u6709\u8bb8\u591a\u5b9e\u7528\u7a0b\u5e8f\u53ef\u7528\u4e8e\u4f7f\u7528\u8fd9\u4e9b\n\u51fd\u6570\u3002\u5bf9\u4e8e\u6b64\u793a\u4f8b\uff0c\u6211\u4eec\u4f7f\u7528\u5df2\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\u7684\u8bb0\u5f55\u6279\u6b21\u5411\u91cf\u3002\u6b64\u5916\uff0c\u5fc5\u987b\u9884\u5148\u77e5\u9053\u6570\u636e\u7684\u6a21\u5f0f\u3002Acero \u5fc5\u987b\u5728\u5f00\u59cb\u4efb\u4f55\u5904\u7406\u4e4b\u524d\u77e5\u9053\u6267\u884c\u56fe\u6bcf\u4e2a\u9636\u6bb5\u7684\u6570\u636e\u6a21\u5f0f\u3002\n\u8fd9\u610f\u5473\u7740\u6211\u4eec\u5fc5\u987b\u4e3a\u6e90\u8282\u70b9\u63d0\u4f9b\u4e0e\u6570\u636e\u672c\u8eab\u5206\u5f00\u7684\u6a21\u5f0f\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u7ed3\u6784\u6765\u4fdd\u5b58\u6570\u636e\u751f\u6210\u5668\u5b9a\u4e49\u3002\u8fd9\u5305\u62ec\u5185\u5b58\u6279\u6b21\u3001\u6a21\u5f0f\u548c\u7528\u4f5c\u6570\u636e\u751f\u6210\u5668\u7684\u51fd\u6570\uff1a"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:"struct BatchesWithSchema {\n  std::vector<cp::ExecBatch> batches;\n  std::shared_ptr<alkaid::Schema> schema;\n  // This method uses internal alkaid utilities to\n  // convert a vector of record batches to an AsyncGenerator of optional batches\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> gen() const {\n    auto opt_batches = ::alkaid::internal::MapVector(\n        [](cp::ExecBatch batch) { return std::make_optional(std::move(batch)); },\n        batches);\n    alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> gen;\n    gen = alkaid::MakeVectorGenerator(std::move(opt_batches));\n    return gen;\n  }\n};\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u751f\u6210\u7528\u4e8e\u8ba1\u7b97\u7684\u6837\u672c\u6279\u6b21\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'alkaid::Result<BatchesWithSchema> MakeBasicBatches() {\n  BatchesWithSchema out;\n  auto field_vector = {alkaid::field("a", alkaid::int32()),\n                       alkaid::field("b", alkaid::boolean())};\n  TURBO_MOVE_OR_RAISE(auto b1_int, GetArrayDataSample<alkaid::Int32Type>({0, 4}));\n  TURBO_MOVE_OR_RAISE(auto b2_int, GetArrayDataSample<alkaid::Int32Type>({5, 6, 7}));\n  TURBO_MOVE_OR_RAISE(auto b3_int, GetArrayDataSample<alkaid::Int32Type>({8, 9, 10}));\n\n  TURBO_MOVE_OR_RAISE(auto b1_bool,\n                        GetArrayDataSample<alkaid::BooleanType>({false, true}));\n  TURBO_MOVE_OR_RAISE(auto b2_bool,\n                        GetArrayDataSample<alkaid::BooleanType>({true, false, true}));\n  TURBO_MOVE_OR_RAISE(auto b3_bool,\n                        GetArrayDataSample<alkaid::BooleanType>({false, true, false}));\n\n  TURBO_MOVE_OR_RAISE(auto b1,\n                        GetExecBatchFromVectors(field_vector, {b1_int, b1_bool}));\n  TURBO_MOVE_OR_RAISE(auto b2,\n                        GetExecBatchFromVectors(field_vector, {b2_int, b2_bool}));\n  TURBO_MOVE_OR_RAISE(auto b3,\n                        GetExecBatchFromVectors(field_vector, {b3_int, b3_bool}));\n\n  out.batches = {b1, b2, b3};\n  out.schema = alkaid::schema(field_vector);\n  return out;\n}\n'})}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"source"})," \u7684\u793a\u4f8b\uff08sink \u7684\u7528\u6cd5\u5728\n",(0,a.jsx)(n.code,{children:"sink<stream_execution_sink_docs>"})," \u4e2d\u6709\u8be6\u7ec6\u8bf4\u660e\uff09\uff1a"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example demonstrating a source and sink node\n///\n/// Source-Table Example\n/// This example shows how a custom source can be used\n/// in an execution plan. This includes source node using pregenerated\n/// data and collecting it into a table.\n///\n/// This sort of custom source is often not needed.  In most cases you can\n/// use a scan (for a dataset source) or a source like table_source, array_vector_source,\n/// exec_batch_source, or record_batch_source (for in-memory data)\nturbo::Status SourceSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(source));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"table_source",children:(0,a.jsx)(n.code,{children:"table_source"})}),"\n",(0,a.jsxs)(n.p,{children:["\u5728\u4e0a\u4e00\u4e2a\u793a\u4f8b\u6e90\u8282\u70b9 ",(0,a.jsx)(n.code,{children:"<stream_execution_source_docs>"}),"\u4e2d\uff0c\u6e90\u8282\u70b9\u7528\u4e8e\u8f93\u5165\u6570\u636e\u3002\u4f46\u662f\u5728\u5f00\u53d1\u5e94\u7528\u7a0b\u5e8f\u65f6\uff0c\u5982\u679c\n\u6570\u636e\u5df2\u7ecf\u4f5c\u4e3a\u8868\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\uff0c\u5219\u4f7f\u7528",(0,a.jsx)(n.code,{children:"TableSourceNodeOptions"}),"\u4f1a\u66f4\u52a0\u5bb9\u6613\uff0c\u6027\u80fd\u4e5f\u66f4\u9ad8\u3002\u5728\u8fd9\u91cc\uff0c\n\u8f93\u5165\u6570\u636e\u53ef\u4ee5\u4f5c\u4e3a",(0,a.jsx)(n.code,{children:"std::shared_ptr<alkaid::Table>"}),"\u4ee5\u53ca",(0,a.jsx)(n.code,{children:"max_batch_size"}),"\u4f20\u9012\u3002",(0,a.jsx)(n.code,{children:"max_batch_size"}),"\u7528\u4e8e\u62c6\u5206\u5927\u578b\u8bb0\u5f55\u6279\u6b21\uff0c\u4ee5\u4fbf\n\u53ef\u4ee5\u5e76\u884c\u5904\u7406\u5b83\u4eec\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5f53\u6e90\u8868\u7684\u6279\u6b21\u8f83\u5c0f\u65f6\uff0c\u8868\u6279\u6b21\u4e0d\u4f1a\u5408\u5e76\u5f62\u6210\u66f4\u5927\u7684\u6279\u6b21\u3002"]}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528",(0,a.jsx)(n.code,{children:"table_source"}),"\u7684\u793a\u4f8b"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a table source node\n///\n/// TableSource-Table Example\n/// This example shows how a table_source can be used\n/// in an execution plan. This includes a table source node\n/// receiving data from a table.  This plan simply collects the\n/// data back into a table but nodes could be added that modify\n/// or transform the data as well (as is shown in later examples)\nturbo::Status TableSourceSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto table, GetTable());\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n  int max_batch_size = 2;\n  auto table_source_options = ac::TableSourceNodeOptions{table, max_batch_size};\n\n  ac::Declaration source{"table_source", std::move(table_source_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(source));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"filter",children:(0,a.jsx)(n.code,{children:"filter"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"filter"})," \u64cd\u4f5c\uff0c\u987e\u540d\u601d\u4e49\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9a\u4e49\u6570\u636e\u8fc7\u6ee4\u6761\u4ef6\u7684\u9009\u9879\u3002\u5b83\u9009\u62e9\u7ed9\u5b9a\u8868\u8fbe\u5f0f\u8ba1\u7b97\u7ed3\u679c\u4e3a true \u7684\n\u884c\u3002\u53ef\u4ee5\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"alkaid::compute::Expression"})," \u7f16\u5199\u8fc7\u6ee4\u5668\uff0c\u5e76\u4e14\u8868\u8fbe\u5f0f\u7684\u8fd4\u56de\u7c7b\u578b\u5e94\u4e3a\u5e03\u5c14\u503c\u3002\u4f8b\u5982\uff0c\n\u5982\u679c\u6211\u4eec\u5e0c\u671b\u4fdd\u7559\u5217 ",(0,a.jsx)(n.code,{children:"b"})," \u7684\u503c\u5927\u4e8e 3 \u7684\u884c\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u8868\u8fbe\u5f0f\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u8fc7\u6ee4\u5668\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a filter node\n///\n/// Source-Filter-Table\n/// This example shows how a filter can be used in an execution plan,\n/// to filter data from a source. The output from the execution plan\n/// is collected into a table.\nturbo::Status ScanFilterSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // specify the filter.  This filter removes all rows where the\n  // value of the "a" column is greater than 3.\n  cp::Expression filter_expr = cp::greater(cp::field_ref("a"), cp::literal(3));\n  // set filter for scanner : on-disk / push-down filtering.\n  // This step can be skipped if you are not reading from disk.\n  options->filter = filter_expr;\n  // empty projection\n  options->projection = cp::project({}, {});\n\n  // construct the scan node\n  std::cout << "Initialized Scanning Options" << std::endl;\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n  std::cout << "Scan node options created" << std::endl;\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n\n  // pipe the scan node into the filter node\n  // Need to set the filter in scan node options and filter node options.\n  // At scan node it is used for on-disk / push-down filtering.\n  // At filter node it is used for in-memory filtering.\n  ac::Declaration filter{\n      "filter", {std::move(scan)}, ac::FilterNodeOptions(std::move(filter_expr))};\n\n  return ExecutePlanAndCollectAsTable(std::move(filter));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"project",children:(0,a.jsx)(n.code,{children:"project"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"project"})," \u64cd\u4f5c\u4f1a\u91cd\u65b0\u6392\u5217\u3001\u5220\u9664\u3001\u8f6c\u6362\u548c\u521b\u5efa\n\u5217\u3002\u6bcf\u4e2a\u8f93\u51fa\u5217\u90fd\u662f\u901a\u8fc7\u9488\u5bf9\u6e90\u8bb0\u5f55\u6279\u6b21\u8bc4\u4f30\u8868\u8fbe\u5f0f\u6765\u8ba1\u7b97\u7684\u3002\u8fd9\u4e9b\u5fc5\u987b\u662f\u6807\u91cf\u8868\u8fbe\u5f0f\n\uff08\u7531\u6807\u91cf\u6587\u5b57\u3001\u5b57\u6bb5\u5f15\u7528\u548c\u6807\u91cf\n\u51fd\u6570\u7ec4\u6210\u7684\u8868\u8fbe\u5f0f\uff0c\u5373\u5143\u7d20\u51fd\u6570\uff0c\u4e3a\u6bcf\u4e2a\u8f93\u5165\u884c\u8fd4\u56de\u4e00\u4e2a\u503c\uff0c\u800c\u4e0e\u6240\u6709\u5176\u4ed6\u884c\u7684\u503c\u65e0\u5173\uff09\u3002\u8fd9\u901a\u8fc7 ",(0,a.jsx)(n.code,{children:"ProjectNodeOptions"})," \u516c\u5f00\uff0c\u5b83\u8981\u6c42\u6bcf\u4e2a\u8f93\u51fa\u5217\u90fd\u6709\u4e00\u4e2a ",(0,a.jsx)(n.code,{children:"alkaid::compute::Expression"}),"\n\u548c\u540d\u79f0\uff08\u5982\u679c\u6ca1\u6709\u63d0\u4f9b\u540d\u79f0\uff0c\u5219\u5c06\u4f7f\u7528 exprs \u7684\u5b57\u7b26\u4e32\u8868\u793a\u5f62\u5f0f\uff09\u3002"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"project"}),"\u793a\u4f8b\uff1a"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a project node\n///\n/// Scan-Project-Table\n/// This example shows how a Scan operation can be used to load the data\n/// into the execution plan, how a project operation can be applied on the\n/// data stream and how the output is collected into a table\nturbo::Status ScanProjectSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // projection\n  cp::Expression a_times_2 = cp::call("multiply", {cp::field_ref("a"), cp::literal(2)});\n  options->projection = cp::project({}, {});\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n  ac::Declaration project{\n      "project", {std::move(scan)}, ac::ProjectNodeOptions({a_times_2})};\n\n  return ExecutePlanAndCollectAsTable(std::move(project));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"aggregate",children:(0,a.jsx)(n.code,{children:"aggregate"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"aggregate"})," \u8282\u70b9\u8ba1\u7b97\u5404\u79cd\u7c7b\u578b\u7684\u6570\u636e\u805a\u5408\u3002"]}),"\n",(0,a.jsxs)(n.p,{children:["Alkaid \u652f\u6301\u4e24\u79cd\u7c7b\u578b\u7684\u805a\u5408\uff1a\u201c\u6807\u91cf\u201d\u805a\u5408\u548c\u201c\u54c8\u5e0c\u201d\u805a\u5408\u3002\u6807\u91cf\u805a\u5408\u5c06\u6570\u7ec4\u6216\u6807\u91cf\u8f93\u5165\u7b80\u5316\u4e3a\u5355\u4e2a\u6807\u91cf\u8f93\u51fa\uff08\u4f8b\u5982\uff0c\u8ba1\u7b97\u5217\u7684\u5e73\u5747\u503c\uff09\u3002\n\u54c8\u5e0c\u805a\u5408\u7684\u4f5c\u7528\u7c7b\u4f3c\u4e8e SQL \u4e2d\u7684 ",(0,a.jsx)(n.code,{children:"GROUP BY"}),"\uff0c\u9996\u5148\u6839\u636e\u4e00\u4e2a\u6216\u591a\u4e2a\u5173\u952e\u5217\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u533a\uff0c\u7136\u540e\u51cf\u5c11\u6bcf\u4e2a\u5206\u533a\u4e2d\u7684\u6570\u636e\u3002",(0,a.jsx)(n.code,{children:"aggregate"}),"\n\u8282\u70b9\u652f\u6301\u8fd9\u4e24\u79cd\u7c7b\u578b\u7684\u8ba1\u7b97\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e00\u6b21\u8ba1\u7b97\u4efb\u610f\u6570\u91cf\u7684\u805a\u5408\u3002"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"AggregateNodeOptions"})," \u7528\u4e8e\u5b9a\u4e49\u805a\u5408\u6807\u51c6\u3002\u5b83\u9700\u8981\u4e00\u4e2a\u805a\u5408\u51fd\u6570\u53ca\u5176\u9009\u9879\u7684\u5217\u8868\uff1b\u8981\u805a\u5408\u7684\u76ee\u6807\u5b57\u6bb5\u5217\u8868\uff0c\u6bcf\u4e2a\u51fd\u6570\u4e00\u4e2a\uff1b\u4ee5\u53ca\n\u8f93\u51fa\u5b57\u6bb5\u7684\u540d\u79f0\u5217\u8868\uff0c\u6bcf\u4e2a\u51fd\u6570\u4e00\u4e2a\u3002\u5728\u54c8\u5e0c\u805a\u5408\u7684\u60c5\u51b5\u4e0b\uff0c\u5b83\u8fd8\u53ef\u4ee5\u9009\u62e9\u7528\u4e8e\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u533a\u7684\u5217\u5217\u8868\u3002\u53ef\u4ee5\u4ece",(0,a.jsx)(n.code,{children:"\u6b64\u805a\u5408\u51fd\u6570\u5217\u8868<aggregation-option-list>"}),"\n\u4e2d\u9009\u62e9\u805a\u5408\u51fd\u6570\u3002"]}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsxs)(n.p,{children:["\u6b64\u8282\u70b9\u662f\u4e00\u4e2a",(0,a.jsx)(n.code,{children:"\u7ba1\u9053\u65ad\u8def\u5668"}),"\uff0c\u5b83\u5c06\u5728\u5185\u5b58\u4e2d\u5b8c\u5168\u5b9e\u73b0\u6570\u636e\u96c6\u3002\u5c06\u6765\uff0c\u5c06\u6dfb\u52a0\u6ea2\u51fa\u673a\u5236\uff0c\u4ee5\u7f13\u89e3\u8fd9\u4e00\u9650\u5236\u3002"]})}),"\n",(0,a.jsxs)(n.p,{children:["\u805a\u5408\u53ef\u4ee5\u5c06\u7ed3\u679c\u4f5c\u4e3a\u7ec4\u6216\u6807\u91cf\u63d0\u4f9b\u3002\u4f8b\u5982\uff0c\u50cf ",(0,a.jsx)(n.code,{children:"hash_count"})," \u8fd9\u6837\u7684\u64cd\u4f5c\u5c06\u6bcf\u4e2a\u552f\u4e00\u8bb0\u5f55\u7684\u8ba1\u6570\u4f5c\u4e3a\u5206\u7ec4\u7ed3\u679c\u63d0\u4f9b\uff0c\u800c\u50cf ",(0,a.jsx)(n.code,{children:"sum"})," \u8fd9\u6837\u7684\u64cd\u4f5c\u5219\u63d0\u4f9b\u5355\u4e2a\u8bb0\u5f55\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u6807\u91cf\u805a\u5408\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing an aggregation node to aggregate an entire table\n///\n/// Source-Aggregation-Table\n/// This example shows how an aggregation operation can be applied on a\n/// execution plan resulting in a scalar output. The source node loads the\n/// data and the aggregation (counting unique types in column \'a\')\n/// is applied on this data. The output is collected into a table (that will\n/// have exactly one row)\nturbo::Status SourceScalarAggregateSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n  auto aggregate_options =\n      ac::AggregateNodeOptions{/*aggregates=*/{{"sum", nullptr, "a", "sum(a)"}}};\n  ac::Declaration aggregate{\n      "aggregate", {std::move(source)}, std::move(aggregate_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(aggregate));\n}\n'})}),"\n",(0,a.jsx)(n.p,{children:"\u7ec4\u805a\u5408\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing an aggregation node to perform a group-by operation\n///\n/// Source-Aggregation-Table\n/// This example shows how an aggregation operation can be applied on a\n/// execution plan resulting in grouped output. The source node loads the\n/// data and the aggregation (counting unique types in column \'a\') is\n/// applied on this data. The output is collected into a table that will contain\n/// one row for each unique combination of group keys.\nturbo::Status SourceGroupAggregateSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n  auto options = std::make_shared<cp::CountOptions>(cp::CountOptions::ONLY_VALID);\n  auto aggregate_options =\n      ac::AggregateNodeOptions{/*aggregates=*/{{"hash_count", options, "a", "count(a)"}},\n                               /*keys=*/{"b"}};\n  ac::Declaration aggregate{\n      "aggregate", {std::move(source)}, std::move(aggregate_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(aggregate));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"sink",children:(0,a.jsx)(n.code,{children:"sink"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"sink"})," \u64cd\u4f5c\u63d0\u4f9b\u8f93\u51fa\uff0c\u662f\u6d41\u5f0f\u6267\u884c\u5b9a\u4e49\u7684\u6700\u7ec8\u8282\u70b9\u3002",(0,a.jsx)(n.code,{children:"SinkNodeOptions"})," \u63a5\u53e3\u7528\u4e8e\u4f20\u9012\u6240\u9700\u7684\u9009\u9879\u3002\u4e0e\u6e90\u64cd\u4f5c\u7b26\u7c7b\n\u4f3c\uff0csink \u64cd\u4f5c\u7b26\u6bcf\u6b21\u8c03\u7528\u65f6\u90fd\u4f1a\u4f7f\u7528\u8fd4\u56de\u8bb0\u5f55\u6279\u5904\u7406\u672a\u6765\u7684\u51fd\u6570\u6765\u516c\u5f00\u8f93\u51fa\u3002\u9884\u8ba1\u8c03\u7528\u8005\u5c06\u91cd\u590d\u8c03\u7528\u6b64\u51fd\u6570\uff0c\u76f4\u5230\u751f\u6210\u5668\u51fd\u6570\u8017\n\u5c3d\uff08\u8fd4\u56de",(0,a.jsx)(n.code,{children:"std::optional::nullopt"}),"\uff09\u3002\u5982\u679c\u6b64\u51fd\u6570\u8c03\u7528\u4e0d\u591f\u9891\u7e41\uff0c\u5219\u8bb0\u5f55\u6279\u5904\u7406\u5c06\u5728\u5185\u5b58\u4e2d\u7d2f\u79ef\u3002\u6267\u884c\u8ba1\u5212\u5e94\u8be5\u53ea\u6709\u4e00\u4e2a\u201c\u7ec8\u7aef\u201d\u8282\u70b9\uff08\u4e00\u4e2a\u63a5\u6536\u5668\u8282\n\u70b9\uff09\u3002",(0,a.jsx)(n.code,{children:"ExecPlan"})," \u53ef\u80fd\u4f1a\u56e0\u53d6\u6d88\u6216\u9519\u8bef\u800c\u63d0\u524d\u7ec8\u6b62\uff0c\u5728\u8f93\u51fa\u88ab\u5b8c\u5168\u4f7f\u7528\u4e4b\u524d\u3002\u4f46\u662f\uff0c\u8be5\u8ba1\u5212\u53ef\u4ee5\u72ec\u7acb\u4e8e\u63a5\u6536\u5668\u5b89\u5168\u5730\u9500\u6bc1\uff0c\u63a5\u6536\u5668\u5c06\u901a\n\u8fc7",(0,a.jsx)(n.code,{children:"exec_plan->finished()"})," \u4fdd\u5b58\u672a\u4f7f\u7528\u7684\u6279\u6b21\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u4f5c\u4e3a\u6e90\u793a\u4f8b\u7684\u4e00\u90e8\u5206\uff0c\u8fd8\u5305\u62ec Sink \u64cd\u4f5c\uff1b"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example demonstrating a source and sink node\n///\n/// Source-Table Example\n/// This example shows how a custom source can be used\n/// in an execution plan. This includes source node using pregenerated\n/// data and collecting it into a table.\n///\n/// This sort of custom source is often not needed.  In most cases you can\n/// use a scan (for a dataset source) or a source like table_source, array_vector_source,\n/// exec_batch_source, or record_batch_source (for in-memory data)\nturbo::Status SourceSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(source));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"consuming_sink",children:(0,a.jsx)(n.code,{children:"consuming_sink"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"consuming_sink"})," \u64cd\u4f5c\u7b26\u662f\u6267\u884c\u8ba1\u5212\u4e2d\u5305\u542b\u6d88\u8d39\u64cd\u4f5c\u7684\u63a5\u6536\u64cd\u4f5c\uff08\u5373\uff0c\u6267\u884c\u8ba1\u5212\u5728\u6d88\u8d39\u5b8c\u6210\u4e4b\u524d\u4e0d\u5e94\u5b8c\u6210\uff09\u3002\n\u4e0e ",(0,a.jsx)(n.code,{children:"sink"})," \u8282\u70b9\u4e0d\u540c\uff0c\u6b64\u8282\u70b9\u63a5\u6536\u9884\u671f\u6d88\u8d39\u6279\u6b21\u7684\u56de\u8c03\u51fd\u6570\u3002\u4e00\u65e6\u6b64\u56de\u8c03\u5b8c\u6210\uff0c\u6267\u884c\u8ba1\u5212\u5c06\u4e0d\u518d\u4fdd\u7559\u5bf9\u6279\u6b21\u7684\u4efb\u4f55\n\u5f15\u7528\u3002\u6d88\u8d39\u51fd\u6570\u53ef\u80fd\u5728\u4e0a\u4e00\u6b21\u8c03\u7528\u5b8c\u6210\u4e4b\u524d\u88ab\u8c03\u7528\u3002\u5982\u679c\u6d88\u8d39\u51fd\u6570\u8fd0\u884c\u4e0d\u591f\u5feb\uff0c\u90a3\u4e48\u8bb8\u591a\u5e76\u53d1\u6267\u884c\u53ef\u80fd\u4f1a\u5806\u79ef\u8d77\u6765\uff0c\u4ece\u800c\u963b\u585e CPU\n\u7ebf\u7a0b\u6c60\u3002\u5728\u6240\u6709\u6d88\u8d39\u51fd\u6570\u56de\u8c03\u5b8c\u6210\u4e4b\u524d\uff0c\u6267\u884c\u8ba1\u5212\u4e0d\u4f1a\u88ab\u6807\u8bb0\u4e3a\u5b8c\u6210\u3002\u4e00\u65e6\u6240\u6709\u6279\u6b21\u90fd\u5df2\u4ea4\u4ed8\uff0c\u6267\u884c\u8ba1\u5212\u5c06\u7b49\u5f85 ",(0,a.jsx)(n.code,{children:"finish"})," \u672a\u6765\u5b8c\u6210\uff0c\u7136\u540e\n\u518d\u5c06\u6267\u884c\u8ba1\u5212\u6807\u8bb0\u4e3a\u5b8c\u6210\u3002\u8fd9\u5141\u8bb8\u5de5\u4f5c\u6d41\uff0c\u5176\u4e2d\u6d88\u8d39\u51fd\u6570\u5c06\u6279\u6b21\u8f6c\u6362\u4e3a\u5f02\u6b65\u4efb\u52a1\uff08\u8fd9\u76ee\u524d\u5728\u6570\u636e\u96c6\u5199\u5165\u8282\u70b9\u5185\u90e8\u5b8c\u6210\uff09\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u4f8b\u5b50\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'// define a Custom SinkNodeConsumer\nstd::atomic<uint32_t> batches_seen{0};\nalkaid::Future<> finish = alkaid::Future<>::Make();\nstruct CustomSinkNodeConsumer : public cp::SinkNodeConsumer {\n\n    CustomSinkNodeConsumer(std::atomic<uint32_t> *batches_seen, alkaid::Future<>finish):\n    batches_seen(batches_seen), finish(std::move(finish)) {}\n    // Consumption logic can be written here\n    turbo::Status Consume(cp::ExecBatch batch) override {\n    // data can be consumed in the expected way\n    // transfer to another system or just do some work\n    // and write to disk\n    (*batches_seen)++;\n    return turbo::Status::OK();\n    }\n\n    alkaid::Future<> Finish() override { return finish; }\n\n    std::atomic<uint32_t> *batches_seen;\n    alkaid::Future<> finish;\n\n};\n\nstd::shared_ptr<CustomSinkNodeConsumer> consumer =\n        std::make_shared<CustomSinkNodeConsumer>(&batches_seen, finish);\n\nalkaid::acero::ExecNode *consuming_sink;\n\nTURBO_MOVE_OR_RAISE(consuming_sink, MakeExecNode("consuming_sink", plan.get(),\n    {source}, cp::ConsumingSinkNodeOptions(consumer)));\n'})}),"\n",(0,a.jsx)(n.p,{children:"Consuming-Sink \u793a\u4f8b:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a consuming sink node\n///\n/// Source-Consuming-Sink\n/// This example shows how the data can be consumed within the execution plan\n/// by using a ConsumingSink node. There is no data output from this execution plan.\nturbo::Status SourceConsumingSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n\n  std::atomic<uint32_t> batches_seen{0};\n  alkaid::Future<> finish = alkaid::Future<>::Make();\n  struct CustomSinkNodeConsumer : public ac::SinkNodeConsumer {\n    CustomSinkNodeConsumer(std::atomic<uint32_t>* batches_seen, alkaid::Future<> finish)\n        : batches_seen(batches_seen), finish(std::move(finish)) {}\n\n    turbo::Status Init(const std::shared_ptr<alkaid::Schema>& schema,\n                       ac::BackpressureControl* backpressure_control,\n                       ac::ExecPlan* plan) override {\n      // This will be called as the plan is started (before the first call to Consume)\n      // and provides the schema of the data coming into the node, controls for pausing /\n      // resuming input, and a pointer to the plan itself which can be used to access\n      // other utilities such as the thread indexer or async task scheduler.\n      return turbo::Status::OK();\n    }\n\n    turbo::Status Consume(cp::ExecBatch batch) override {\n      (*batches_seen)++;\n      return turbo::Status::OK();\n    }\n\n    alkaid::Future<> Finish() override {\n      // Here you can perform whatever (possibly async) cleanup is needed, e.g. closing\n      // output file handles and flushing remaining work\n      return alkaid::Future<>::MakeFinished();\n    }\n\n    std::atomic<uint32_t>* batches_seen;\n    alkaid::Future<> finish;\n  };\n  std::shared_ptr<CustomSinkNodeConsumer> consumer =\n      std::make_shared<CustomSinkNodeConsumer>(&batches_seen, finish);\n\n  ac::Declaration consuming_sink{"consuming_sink",\n                                 {std::move(source)},\n                                 ac::ConsumingSinkNodeOptions(std::move(consumer))};\n\n  // Since we are consuming the data within the plan there is no output and we simply\n  // run the plan to completion instead of collecting into a table.\n  TURBO_RETURN_NOT_OK(ac::DeclarationToStatus(std::move(consuming_sink)));\n\n  std::cout << "The consuming sink node saw " << batches_seen.load() << " batches"\n            << std::endl;\n  return turbo::Status::OK();\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"order_by_sink",children:(0,a.jsx)(n.code,{children:"order_by_sink"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"order_by_sink"})," \u64cd\u4f5c\u662f ",(0,a.jsx)(n.code,{children:"sink"})," \u64cd\u4f5c\u7684\u6269\u5c55\u3002\u6b64\u64cd\u4f5c\u901a\u8fc7\u63d0\u4f9b ",(0,a.jsx)(n.code,{children:"OrderBySinkNodeOptions"})," \u6765\u4fdd\u8bc1\u6d41\u7684\u6392\u5e8f\u3002\n\u8fd9\u91cc\u63d0\u4f9b\u4e86 ",(0,a.jsx)(n.code,{children:"alkaid::compute::SortOptions"})," \u6765\u5b9a\u4e49\u54ea\u4e9b\u5217\u7528\u4e8e\u6392\u5e8f\u4ee5\u53ca\u662f\u5426\u6309\u5347\u5e8f\u6216\u964d\u5e8f\u503c\u6392\u5e8f\u3002"]}),"\n",(0,a.jsx)(n.div,{}),"\n",(0,a.jsx)(n.p,{children:"\u6b64\u8282\u70b9\u662f\u4e00\u4e2a\u201c\u7ba1\u9053\u65ad\u8def\u5668\u201d\uff0c\u5b83\u5c06\u5728\u5185\u5b58\u4e2d\u5b8c\u5168\u5b9e\u73b0\u6570\u636e\u96c6\u3002\u5c06\u6765\uff0c\u5c06\u6dfb\u52a0\u6ea2\u51fa\u673a\u5236\uff0c\u4ee5\u7f13\u89e3\u8fd9\u4e00\u9650\u5236\u3002\n:::"}),"\n",(0,a.jsx)(n.p,{children:"Order-By-Sink \u793a\u4f8b:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'turbo::Status ExecutePlanAndCollectAsTableWithCustomSink(\n    std::shared_ptr<ac::ExecPlan> plan, std::shared_ptr<alkaid::Schema> schema,\n    alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen) {\n  // translate sink_gen (async) to sink_reader (sync)\n  std::shared_ptr<alkaid::RecordBatchReader> sink_reader =\n      ac::MakeGeneratorReader(schema, std::move(sink_gen), alkaid::default_memory_pool());\n\n  // validate the ExecPlan\n  TURBO_RETURN_NOT_OK(plan->Validate());\n  std::cout << "ExecPlan created : " << plan->ToString() << std::endl;\n  // start the ExecPlan\n  plan->StartProducing();\n\n  // collect sink_reader into a Table\n  std::shared_ptr<alkaid::Table> response_table;\n\n  TURBO_MOVE_OR_RAISE(response_table,\n                        alkaid::Table::FromRecordBatchReader(sink_reader.get()));\n\n  std::cout << "Results : " << response_table->ToString() << std::endl;\n\n  // stop producing\n  plan->StopProducing();\n  // plan mark finished\n  auto future = plan->finished();\n  return future.status();\n}\n\n/// \\brief An example showing an order-by node\n///\n/// Source-OrderBy-Sink\n/// In this example, the data enters through the source node\n/// and the data is ordered in the sink node. The order can be\n/// ASCENDING or DESCENDING and it is configurable. The output\n/// is obtained as a table from the sink node.\nturbo::Status SourceOrderBySinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<ac::ExecPlan> plan,\n                        ac::ExecPlan::Make(*cp::threaded_exec_context()));\n\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeSortTestBasicBatches());\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n  TURBO_MOVE_OR_RAISE(ac::ExecNode * source,\n                        ac::MakeExecNode("source", plan.get(), {}, source_node_options));\n\n  TURBO_RETURN_NOT_OK(ac::MakeExecNode(\n      "order_by_sink", plan.get(), {source},\n      ac::OrderBySinkNodeOptions{\n          cp::SortOptions{{cp::SortKey{"a", cp::SortOrder::Descending}}}, &sink_gen}));\n\n  return ExecutePlanAndCollectAsTableWithCustomSink(plan, basic_data.schema, sink_gen);\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"select_k_sink",children:(0,a.jsx)(n.code,{children:"select_k_sink"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"select_k_sink"})," \u9009\u9879\u5141\u8bb8\u9009\u62e9\u9876\u90e8/\u5e95\u90e8 K \u4e2a\u5143\u7d20\uff0c"]}),"\n",(0,a.jsxs)(n.p,{children:["\u7c7b\u4f3c\u4e8e SQL ",(0,a.jsx)(n.code,{children:"ORDER BY ... LIMIT K"})," \u5b50\u53e5\u3002",(0,a.jsx)(n.code,{children:"SelectKOptions"})]}),"\n",(0,a.jsxs)(n.p,{children:["\u662f\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"OrderBySinkNode"})," \u5b9a\u4e49\u5b9a\u4e49\u7684\u3002\u6b64\u9009\u9879\u8fd4\u56de"]}),"\n",(0,a.jsx)(n.p,{children:"\u4e00\u4e2a\u63a5\u6536\u8f93\u5165\u7136\u540e\u8ba1\u7b97 top_k/bottom_k \u7684\u63a5\u6536\u5668\u8282\u70b9\u3002"}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsx)(n.p,{children:"\u6b64\u8282\u70b9\u662f\u4e00\u4e2a\u201c\u7ba1\u9053\u65ad\u8def\u5668\u201d\uff0c\u5c06\u5728\u5185\u5b58\u4e2d\u5b8c\u5168\u5b9e\u73b0\u8f93\u5165\u3002\u5c06\u6765\uff0c\u5c06\u6dfb\u52a0\u6ea2\u51fa\u673a\u5236\uff0c\u8fd9\u5e94\u8be5\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u9650\u5236\u3002"})}),"\n",(0,a.jsx)(n.p,{children:"SelectK \u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a select-k node\n///\n/// Source-KSelect\n/// This example shows how K number of elements can be selected\n/// either from the top or bottom. The output node is a modified\n/// sink node where output can be obtained as a table.\nturbo::Status SourceKSelectExample() {\n  TURBO_MOVE_OR_RAISE(auto input, MakeGroupableBatches());\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<ac::ExecPlan> plan,\n                        ac::ExecPlan::Make(*cp::threaded_exec_context()));\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  TURBO_MOVE_OR_RAISE(\n      ac::ExecNode * source,\n      ac::MakeExecNode("source", plan.get(), {},\n                       ac::SourceNodeOptions{input.schema, input.gen()}));\n\n  cp::SelectKOptions options = cp::SelectKOptions::TopKDefault(/*k=*/2, {"i32"});\n\n  TURBO_RETURN_NOT_OK(ac::MakeExecNode("select_k_sink", plan.get(), {source},\n                                       ac::SelectKSinkNodeOptions{options, &sink_gen}));\n\n  auto schema = alkaid::schema(\n      {alkaid::field("i32", alkaid::int32()), alkaid::field("str", alkaid::utf8())});\n\n  return ExecutePlanAndCollectAsTableWithCustomSink(plan, schema, sink_gen);\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"table_sink",children:(0,a.jsx)(n.code,{children:"table_sink"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"table_sink"})," \u8282\u70b9\u63d0\u4f9b\u4e86\u5c06\u8f93\u51fa\u4f5c\u4e3a\u5185\u5b58\u8868\u63a5\u6536\u7684\u529f\u80fd\u3002\u8fd9\u6bd4\u6d41\u6267\u884c\u5f15\u64ce\u63d0\u4f9b\u7684\u5176\u4ed6\u63a5\u6536\u5668\u8282\u70b9\u66f4\u6613\u4e8e\u4f7f\u7528\uff0c\u4f46\u53ea\u6709\u5f53\u8f93\u51fa\n\u9002\u5408\u5185\u5b58\u65f6\u624d\u6709\u610f\u4e49\u3002\u8be5\u8282\u70b9\u662f\u4f7f\u7528",(0,a.jsx)(n.code,{children:"TableSinkNodeOptions"}),"\u521b\u5efa\u7684\u3002"]}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"table_sink"})," \u7684\u793a\u4f8b"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a table sink node\n///\n/// TableSink Example\n/// This example shows how a table_sink can be used\n/// in an execution plan. This includes a source node\n/// receiving data as batches and the table sink node\n/// which emits the output as a table.\nturbo::Status TableSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<ac::ExecPlan> plan,\n                        ac::ExecPlan::Make(*cp::threaded_exec_context()));\n\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  TURBO_MOVE_OR_RAISE(ac::ExecNode * source,\n                        ac::MakeExecNode("source", plan.get(), {}, source_node_options));\n\n  std::shared_ptr<alkaid::Table> output_table;\n  auto table_sink_options = ac::TableSinkNodeOptions{&output_table};\n\n  TURBO_RETURN_NOT_OK(\n      ac::MakeExecNode("table_sink", plan.get(), {source}, table_sink_options));\n  // validate the ExecPlan\n  TURBO_RETURN_NOT_OK(plan->Validate());\n  std::cout << "ExecPlan created : " << plan->ToString() << std::endl;\n  // start the ExecPlan\n  plan->StartProducing();\n\n  // Wait for the plan to finish\n  auto finished = plan->finished();\n  RETURN_NOT_OK(finished.status());\n  std::cout << "Results : " << output_table->ToString() << std::endl;\n  return turbo::Status::OK();\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"scan",children:(0,a.jsx)(n.code,{children:"scan"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"scan"})," \u662f\u7528\u4e8e\u52a0\u8f7d\u548c\u5904\u7406\u6570\u636e\u96c6\u7684\u64cd\u4f5c\u3002\u5f53\u60a8\u7684\u8f93\u5165\u662f\u6570\u636e\u96c6\u65f6\uff0c\u5b83\u5e94\u8be5\u4f18\u4e8e\u66f4\u901a\u7528\u7684 ",(0,a.jsx)(n.code,{children:"source"})," \u8282\u70b9\u3002\u8be5\u884c\u4e3a\n\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"alkaid::dataset::ScanNodeOptions"})," \u5b9a\u4e49\u3002\u6709\u5173\u6570\u636e\u96c6\u548c\u5404\u79cd\u626b\u63cf\u9009\u9879\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 ",(0,a.jsx)(n.code,{children:"../dataset"}),"\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u6b64\u8282\u70b9\u80fd\u591f\u5c06\u4e0b\u63a8\u8fc7\u6ee4\u5668\u5e94\u7528\u4e8e\u6587\u4ef6\u8bfb\u53d6\u5668\uff0c\u4ece\u800c\u51cf\u5c11\u9700\u8981\u8bfb\u53d6\u7684\u6570\u636e\u91cf\u3002\u8fd9\u610f\u5473\u7740\u60a8\u53ef\u4ee5\u5411\u626b\u63cf\u8282\u70b9\u63d0\u4f9b\u4e0e FilterNode \u76f8\u540c\u7684\u8fc7\u6ee4\u5668\u8868\u8fbe\u5f0f\uff0c\u56e0\u4e3a\u8fc7\u6ee4\u662f\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u5730\u65b9\u5b8c\u6210\u7684\u3002"}),"\n",(0,a.jsx)(n.p,{children:"\u626b\u63cf\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example demonstrating a scan and sink node\n///\n/// Scan-Table\n/// This example shows how scan operation can be applied on a dataset.\n/// There are operations that can be applied on the scan (project, filter)\n/// and the input data can be processed. The output is obtained as a table\nturbo::Status ScanSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  options->projection = cp::project({}, {});  // create empty projection\n\n  // construct the scan node\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(scan));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"write",children:(0,a.jsx)(n.code,{children:"write"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"write"})," \u8282\u70b9\u4f7f\u7528 Alkaid \u4e2d\u7684 ",(0,a.jsx)(n.code,{children:"../dataset"})," \u529f\u80fd\u5c06\u67e5\u8be2\u7ed3\u679c\u4fdd\u5b58\u4e3a Parquet\u3001Feather\u3001CSV \u7b49\u683c\u5f0f\u7684\u6587\u4ef6\u6570\u636e\u96c6\u3002\u5199\u5165\u9009\u9879\u901a\n\u8fc7 ",(0,a.jsx)(n.code,{children:"alkaid::dataset::WriteNodeOptions"})," \u63d0\u4f9b\uff0c\u800c ",(0,a.jsx)(n.code,{children:"alkaid::dataset::FileSystemDatasetWriteOptions"})," \u53c8\u5305\n\u542b ",(0,a.jsx)(n.code,{children:"alkaid::dataset::FileSystemDatasetWriteOptions"}),"\u3002",(0,a.jsx)(n.code,{children:"alkaid::dataset::FileSystemDatasetWriteOptions"})," \u63d0\n\u4f9b\u5bf9\u5199\u5165\u6570\u636e\u96c6\u7684\u63a7\u5236\uff0c\u5305\u62ec\u8f93\u51fa\u76ee\u5f55\u3001\u6587\u4ef6\u547d\u540d\u65b9\u6848\u7b49\u9009\u9879\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u5199\u5165\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a write node\n/// \\param file_path The destination to write to\n///\n/// Scan-Filter-Write\n/// This example shows how scan node can be used to load the data\n/// and after processing how it can be written to disk.\nturbo::Status ScanFilterWriteExample(const std::string& file_path) {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // empty projection\n  options->projection = cp::project({}, {});\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  std::string root_path = "";\n  std::string uri = "file://" + file_path;\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::fs::FileSystem> filesystem,\n                        alkaid::fs::FileSystemFromUri(uri, &root_path));\n\n  auto base_path = root_path + "/parquet_dataset";\n  // Uncomment the following line, if run repeatedly\n  // TURBO_RETURN_NOT_OK(filesystem->DeleteDirContents(base_path));\n  TURBO_RETURN_NOT_OK(filesystem->CreateDir(base_path));\n\n  // The partition schema determines which fields are part of the partitioning.\n  auto partition_schema = alkaid::schema({alkaid::field("a", alkaid::int32())});\n  // We\'ll use Hive-style partitioning,\n  // which creates directories with "key=value" pairs.\n\n  auto partitioning =\n      std::make_shared<alkaid::dataset::HivePartitioning>(partition_schema);\n  // We\'ll write Parquet files.\n  auto format = std::make_shared<alkaid::dataset::ParquetFileFormat>();\n\n  alkaid::dataset::FileSystemDatasetWriteOptions write_options;\n  write_options.file_write_options = format->DefaultWriteOptions();\n  write_options.filesystem = filesystem;\n  write_options.base_dir = base_path;\n  write_options.partitioning = partitioning;\n  write_options.basename_template = "part{i}.parquet";\n\n  alkaid::dataset::WriteNodeOptions write_node_options{write_options};\n\n  ac::Declaration write{"write", {std::move(scan)}, std::move(write_node_options)};\n\n  // Since the write node has no output we simply run the plan to completion and the\n  // data should be written\n  TURBO_RETURN_NOT_OK(ac::DeclarationToStatus(std::move(write)));\n\n  std::cout << "Dataset written to " << base_path << std::endl;\n  return turbo::Status::OK();\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"union",children:(0,a.jsx)(n.code,{children:"union"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"union"})," \u5c06\u5177\u6709\u76f8\u540c\u67b6\u6784\u7684\u591a\u4e2a\u6570\u636e\u6d41\u5408\u5e76\u4e3a\u4e00\u4e2a\uff0c\n\u7c7b\u4f3c\u4e8e SQL ",(0,a.jsx)(n.code,{children:"UNION ALL"})," \u5b50\u53e5\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u4ee5\u4e0b\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u4e24\u4e2a\u6570\u636e\u6e90\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002"}),"\n",(0,a.jsx)(n.p,{children:"\u8054\u5408\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a union node\n///\n/// Source-Union-Table\n/// This example shows how a union operation can be applied on two\n/// data sources. The output is collected into a table.\nturbo::Status SourceUnionSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  ac::Declaration lhs{"source",\n                      ac::SourceNodeOptions{basic_data.schema, basic_data.gen()}};\n  lhs.label = "lhs";\n  ac::Declaration rhs{"source",\n                      ac::SourceNodeOptions{basic_data.schema, basic_data.gen()}};\n  rhs.label = "rhs";\n  ac::Declaration union_plan{\n      "union", {std::move(lhs), std::move(rhs)}, ac::ExecNodeOptions{}};\n\n  return ExecutePlanAndCollectAsTable(std::move(union_plan));\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"hash_join",children:(0,a.jsx)(n.code,{children:"hash_join"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"hash_join"})," \u64cd\u4f5c\u63d0\u4f9b\u5173\u7cfb\u4ee3\u6570\u64cd\u4f5c\uff0c\u4f7f\u7528\u57fa\u4e8e\u54c8\u5e0c\u7684\u7b97\u6cd5\u8fdb\u884c\u8fde\u63a5\u3002",(0,a.jsx)(n.code,{children:"HashJoinNodeOptions"})," \u5305\u542b\u5b9a\u4e49\u8fde\u63a5\u6240\u9700\u7684\u9009\u9879\u3002\nhash_join \u652f\u6301 ",(0,a.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Join_(SQL)",children:"\u5de6/\u53f3/\u5168\u534a/\u53cd/\u5916\u8fde\u63a5"}),"\u3002\u6b64\u5916\uff0c\u53ef\u4ee5\u901a\u8fc7\u8fde\u63a5\u9009\u9879\u8bbe\n\u7f6e\u8fde\u63a5\u952e\uff08\u5373\u8981\u8fde\u63a5\u7684\u5217\uff09\u548c\u540e\u7f00\uff08\u5373\u540e\u7f00\u672f\u8bed\uff0c\u5982\u201c_x\u201d\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5728\u5de6\u5173\u7cfb\u548c\u53f3\u5173\u7cfb\u4e2d\u91cd\u590d\u7684\u5217\u540d\u7684\u540e\u7f00\u9644\u52a0\uff09\u3002\n",(0,a.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Hash_join",children:"\u9605\u8bfb\u66f4\u591a\u5173\u4e8e hash-joins"}),"\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"Hash-Join \u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'/// \\brief An example showing a hash join node\n///\n/// Source-HashJoin-Table\n/// This example shows how source node gets the data and how a self-join\n/// is applied on the data. The join options are configurable. The output\n/// is collected into a table.\nturbo::Status SourceHashJoinSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto input, MakeGroupableBatches());\n\n  ac::Declaration left{"source", ac::SourceNodeOptions{input.schema, input.gen()}};\n  ac::Declaration right{"source", ac::SourceNodeOptions{input.schema, input.gen()}};\n\n  ac::HashJoinNodeOptions join_opts{\n      ac::JoinType::INNER,\n      /*left_keys=*/{"str"},\n      /*right_keys=*/{"str"}, cp::literal(true), "l_", "r_"};\n\n  ac::Declaration hashjoin{\n      "hashjoin", {std::move(left), std::move(right)}, std::move(join_opts)};\n\n  return ExecutePlanAndCollectAsTable(std::move(hashjoin));\n}\n'})}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsxs)(n.p,{children:["\u8fd9\u4e9b\u8282\u70b9\u7684\u793a\u4f8b\u53ef\u4ee5\u5728 Alkaid \u6e90\u4e2d\u7684\n",(0,a.jsx)(n.code,{children:"cpp/examples/alkaid/execution_plan_documentation_examples.cc"})," \u4e2d\u627e\u5230\u3002"]}),"\n",(0,a.jsx)(n.p,{children:"\u5b8c\u6574\u793a\u4f8b\uff1a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-cpp",children:'#include <alkaid/array.h>\n#include <alkaid/builder.h>\n\n#include <alkaid/acero/exec_plan.h>\n#include <alkaid/compute/api.h>\n#include <alkaid/compute/api_vector.h>\n#include <alkaid/compute/cast.h>\n\n#include <alkaid/csv/api.h>\n\n#include <alkaid/dataset/dataset.h>\n#include <alkaid/dataset/file_base.h>\n#include <alkaid/dataset/file_parquet.h>\n#include <alkaid/dataset/plan.h>\n#include <alkaid/dataset/scanner.h>\n\n#include <alkaid/io/interfaces.h>\n#include <alkaid/io/memory.h>\n\n#include <alkaid/result.h>\n#include <alkaid/status.h>\n#include <alkaid/table.h>\n\n#include <alkaid/ipc/api.h>\n\n#include <alkaid/util/future.h>\n#include <alkaid/util/range.h>\n#include <alkaid/util/thread_pool.h>\n#include <alkaid/util/vector.h>\n\n#include <iostream>\n#include <memory>\n#include <utility>\n\n// Demonstrate various operators in Alkaid Streaming Execution Engine\n\nnamespace cp = ::alkaid::compute;\nnamespace ac = ::alkaid::acero;\n\nconstexpr char kSep[] = "******";\n\nvoid PrintBlock(const std::string& msg) {\n  std::cout << "\\n\\t" << kSep << " " << msg << " " << kSep << "\\n" << std::endl;\n}\n\ntemplate <typename TYPE,\n          typename = typename std::enable_if<alkaid::is_number_type<TYPE>::value |\n                                             alkaid::is_boolean_type<TYPE>::value |\n                                             alkaid::is_temporal_type<TYPE>::value>::type>\nalkaid::Result<std::shared_ptr<alkaid::Array>> GetArrayDataSample(\n    const std::vector<typename TYPE::c_type>& values) {\n  using AlkaidBuilderType = typename alkaid::TypeTraits<TYPE>::BuilderType;\n  AlkaidBuilderType builder;\n  TURBO_RETURN_NOT_OK(builder.Reserve(values.size()));\n  TURBO_RETURN_NOT_OK(builder.AppendValues(values));\n  return builder.Finish();\n}\n\ntemplate <class TYPE>\nalkaid::Result<std::shared_ptr<alkaid::Array>> GetBinaryArrayDataSample(\n    const std::vector<std::string>& values) {\n  using AlkaidBuilderType = typename alkaid::TypeTraits<TYPE>::BuilderType;\n  AlkaidBuilderType builder;\n  TURBO_RETURN_NOT_OK(builder.Reserve(values.size()));\n  TURBO_RETURN_NOT_OK(builder.AppendValues(values));\n  return builder.Finish();\n}\n\nalkaid::Result<std::shared_ptr<alkaid::RecordBatch>> GetSampleRecordBatch(\n    const alkaid::ArrayVector array_vector, const alkaid::FieldVector& field_vector) {\n  std::shared_ptr<alkaid::RecordBatch> record_batch;\n  TURBO_MOVE_OR_RAISE(auto struct_result,\n                        alkaid::StructArray::Make(array_vector, field_vector));\n  return record_batch->FromStructArray(struct_result);\n}\n\n/// \\brief Create a sample table\n/// The table\'s contents will be:\n/// a,b\n/// 1,null\n/// 2,true\n/// null,true\n/// 3,false\n/// null,true\n/// 4,false\n/// 5,null\n/// 6,false\n/// 7,false\n/// 8,true\n/// \\return The created table\n\nalkaid::Result<std::shared_ptr<alkaid::Table>> GetTable() {\n  auto null_long = std::numeric_limits<int64_t>::quiet_NaN();\n  TURBO_MOVE_OR_RAISE(auto int64_array,\n                        GetArrayDataSample<alkaid::Int64Type>(\n                            {1, 2, null_long, 3, null_long, 4, 5, 6, 7, 8}));\n\n  alkaid::BooleanBuilder boolean_builder;\n  std::shared_ptr<alkaid::BooleanArray> bool_array;\n\n  std::vector<uint8_t> bool_values = {false, true,  true,  false, true,\n                                      false, false, false, false, true};\n  std::vector<bool> is_valid = {false, true,  true, true, true,\n                                true,  false, true, true, true};\n\n  TURBO_RETURN_NOT_OK(boolean_builder.Reserve(10));\n\n  TURBO_RETURN_NOT_OK(boolean_builder.AppendValues(bool_values, is_valid));\n\n  TURBO_RETURN_NOT_OK(boolean_builder.Finish(&bool_array));\n\n  auto record_batch =\n      alkaid::RecordBatch::Make(alkaid::schema({alkaid::field("a", alkaid::int64()),\n                                              alkaid::field("b", alkaid::boolean())}),\n                               10, {int64_array, bool_array});\n  TURBO_MOVE_OR_RAISE(auto table, alkaid::Table::FromRecordBatches({record_batch}));\n  return table;\n}\n\n/// \\brief Create a sample dataset\n/// \\return An in-memory dataset based on GetTable()\nalkaid::Result<std::shared_ptr<alkaid::dataset::Dataset>> GetDataset() {\n  TURBO_MOVE_OR_RAISE(auto table, GetTable());\n  auto ds = std::make_shared<alkaid::dataset::InMemoryDataset>(table);\n  return ds;\n}\n\nalkaid::Result<cp::ExecBatch> GetExecBatchFromVectors(\n    const alkaid::FieldVector& field_vector, const alkaid::ArrayVector& array_vector) {\n  std::shared_ptr<alkaid::RecordBatch> record_batch;\n  TURBO_MOVE_OR_RAISE(auto res_batch, GetSampleRecordBatch(array_vector, field_vector));\n  cp::ExecBatch batch{*res_batch};\n  return batch;\n}\n\n// (Doc section: BatchesWithSchema Definition)\nstruct BatchesWithSchema {\n  std::vector<cp::ExecBatch> batches;\n  std::shared_ptr<alkaid::Schema> schema;\n  // This method uses internal alkaid utilities to\n  // convert a vector of record batches to an AsyncGenerator of optional batches\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> gen() const {\n    auto opt_batches = ::alkaid::internal::MapVector(\n        [](cp::ExecBatch batch) { return std::make_optional(std::move(batch)); },\n        batches);\n    alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> gen;\n    gen = alkaid::MakeVectorGenerator(std::move(opt_batches));\n    return gen;\n  }\n};\n// (Doc section: BatchesWithSchema Definition)\n\n// (Doc section: MakeBasicBatches Definition)\nalkaid::Result<BatchesWithSchema> MakeBasicBatches() {\n  BatchesWithSchema out;\n  auto field_vector = {alkaid::field("a", alkaid::int32()),\n                       alkaid::field("b", alkaid::boolean())};\n  TURBO_MOVE_OR_RAISE(auto b1_int, GetArrayDataSample<alkaid::Int32Type>({0, 4}));\n  TURBO_MOVE_OR_RAISE(auto b2_int, GetArrayDataSample<alkaid::Int32Type>({5, 6, 7}));\n  TURBO_MOVE_OR_RAISE(auto b3_int, GetArrayDataSample<alkaid::Int32Type>({8, 9, 10}));\n\n  TURBO_MOVE_OR_RAISE(auto b1_bool,\n                        GetArrayDataSample<alkaid::BooleanType>({false, true}));\n  TURBO_MOVE_OR_RAISE(auto b2_bool,\n                        GetArrayDataSample<alkaid::BooleanType>({true, false, true}));\n  TURBO_MOVE_OR_RAISE(auto b3_bool,\n                        GetArrayDataSample<alkaid::BooleanType>({false, true, false}));\n\n  TURBO_MOVE_OR_RAISE(auto b1,\n                        GetExecBatchFromVectors(field_vector, {b1_int, b1_bool}));\n  TURBO_MOVE_OR_RAISE(auto b2,\n                        GetExecBatchFromVectors(field_vector, {b2_int, b2_bool}));\n  TURBO_MOVE_OR_RAISE(auto b3,\n                        GetExecBatchFromVectors(field_vector, {b3_int, b3_bool}));\n\n  out.batches = {b1, b2, b3};\n  out.schema = alkaid::schema(field_vector);\n  return out;\n}\n// (Doc section: MakeBasicBatches Definition)\n\nalkaid::Result<BatchesWithSchema> MakeSortTestBasicBatches() {\n  BatchesWithSchema out;\n  auto field = alkaid::field("a", alkaid::int32());\n  TURBO_MOVE_OR_RAISE(auto b1_int, GetArrayDataSample<alkaid::Int32Type>({1, 3, 0, 2}));\n  TURBO_MOVE_OR_RAISE(auto b2_int,\n                        GetArrayDataSample<alkaid::Int32Type>({121, 101, 120, 12}));\n  TURBO_MOVE_OR_RAISE(auto b3_int,\n                        GetArrayDataSample<alkaid::Int32Type>({10, 110, 210, 121}));\n  TURBO_MOVE_OR_RAISE(auto b4_int,\n                        GetArrayDataSample<alkaid::Int32Type>({51, 101, 2, 34}));\n  TURBO_MOVE_OR_RAISE(auto b5_int,\n                        GetArrayDataSample<alkaid::Int32Type>({11, 31, 1, 12}));\n  TURBO_MOVE_OR_RAISE(auto b6_int,\n                        GetArrayDataSample<alkaid::Int32Type>({12, 101, 120, 12}));\n  TURBO_MOVE_OR_RAISE(auto b7_int,\n                        GetArrayDataSample<alkaid::Int32Type>({0, 110, 210, 11}));\n  TURBO_MOVE_OR_RAISE(auto b8_int,\n                        GetArrayDataSample<alkaid::Int32Type>({51, 10, 2, 3}));\n\n  TURBO_MOVE_OR_RAISE(auto b1, GetExecBatchFromVectors({field}, {b1_int}));\n  TURBO_MOVE_OR_RAISE(auto b2, GetExecBatchFromVectors({field}, {b2_int}));\n  TURBO_MOVE_OR_RAISE(auto b3,\n                        GetExecBatchFromVectors({field, field}, {b3_int, b8_int}));\n  TURBO_MOVE_OR_RAISE(auto b4,\n                        GetExecBatchFromVectors({field, field, field, field},\n                                                {b4_int, b5_int, b6_int, b7_int}));\n  out.batches = {b1, b2, b3, b4};\n  out.schema = alkaid::schema({field});\n  return out;\n}\n\nalkaid::Result<BatchesWithSchema> MakeGroupableBatches(int multiplicity = 1) {\n  BatchesWithSchema out;\n  auto fields = {alkaid::field("i32", alkaid::int32()), alkaid::field("str", alkaid::utf8())};\n  TURBO_MOVE_OR_RAISE(auto b1_int, GetArrayDataSample<alkaid::Int32Type>({12, 7, 3}));\n  TURBO_MOVE_OR_RAISE(auto b2_int, GetArrayDataSample<alkaid::Int32Type>({-2, -1, 3}));\n  TURBO_MOVE_OR_RAISE(auto b3_int, GetArrayDataSample<alkaid::Int32Type>({5, 3, -8}));\n  TURBO_MOVE_OR_RAISE(auto b1_str, GetBinaryArrayDataSample<alkaid::StringType>(\n                                         {"alpha", "beta", "alpha"}));\n  TURBO_MOVE_OR_RAISE(auto b2_str, GetBinaryArrayDataSample<alkaid::StringType>(\n                                         {"alpha", "gamma", "alpha"}));\n  TURBO_MOVE_OR_RAISE(auto b3_str, GetBinaryArrayDataSample<alkaid::StringType>(\n                                         {"gamma", "beta", "alpha"}));\n  TURBO_MOVE_OR_RAISE(auto b1, GetExecBatchFromVectors(fields, {b1_int, b1_str}));\n  TURBO_MOVE_OR_RAISE(auto b2, GetExecBatchFromVectors(fields, {b2_int, b2_str}));\n  TURBO_MOVE_OR_RAISE(auto b3, GetExecBatchFromVectors(fields, {b3_int, b3_str}));\n  out.batches = {b1, b2, b3};\n\n  size_t batch_count = out.batches.size();\n  for (int repeat = 1; repeat < multiplicity; ++repeat) {\n    for (size_t i = 0; i < batch_count; ++i) {\n      out.batches.push_back(out.batches[i]);\n    }\n  }\n\n  out.schema = alkaid::schema(fields);\n  return out;\n}\n\nturbo::Status ExecutePlanAndCollectAsTable(ac::Declaration plan) {\n  // collect sink_reader into a Table\n  std::shared_ptr<alkaid::Table> response_table;\n  TURBO_MOVE_OR_RAISE(response_table, ac::DeclarationToTable(std::move(plan)));\n\n  std::cout << "Results : " << response_table->ToString() << std::endl;\n\n  return turbo::Status::OK();\n}\n\n// (Doc section: Scan Example)\n\n/// \\brief An example demonstrating a scan and sink node\n///\n/// Scan-Table\n/// This example shows how scan operation can be applied on a dataset.\n/// There are operations that can be applied on the scan (project, filter)\n/// and the input data can be processed. The output is obtained as a table\nturbo::Status ScanSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  options->projection = cp::project({}, {});  // create empty projection\n\n  // construct the scan node\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(scan));\n}\n// (Doc section: Scan Example)\n\n// (Doc section: Source Example)\n\n/// \\brief An example demonstrating a source and sink node\n///\n/// Source-Table Example\n/// This example shows how a custom source can be used\n/// in an execution plan. This includes source node using pregenerated\n/// data and collecting it into a table.\n///\n/// This sort of custom source is often not needed.  In most cases you can\n/// use a scan (for a dataset source) or a source like table_source, array_vector_source,\n/// exec_batch_source, or record_batch_source (for in-memory data)\nturbo::Status SourceSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(source));\n}\n// (Doc section: Source Example)\n\n// (Doc section: Table Source Example)\n\n/// \\brief An example showing a table source node\n///\n/// TableSource-Table Example\n/// This example shows how a table_source can be used\n/// in an execution plan. This includes a table source node\n/// receiving data from a table.  This plan simply collects the\n/// data back into a table but nodes could be added that modify\n/// or transform the data as well (as is shown in later examples)\nturbo::Status TableSourceSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto table, GetTable());\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n  int max_batch_size = 2;\n  auto table_source_options = ac::TableSourceNodeOptions{table, max_batch_size};\n\n  ac::Declaration source{"table_source", std::move(table_source_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(source));\n}\n// (Doc section: Table Source Example)\n\n// (Doc section: Filter Example)\n\n/// \\brief An example showing a filter node\n///\n/// Source-Filter-Table\n/// This example shows how a filter can be used in an execution plan,\n/// to filter data from a source. The output from the execution plan\n/// is collected into a table.\nturbo::Status ScanFilterSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // specify the filter.  This filter removes all rows where the\n  // value of the "a" column is greater than 3.\n  cp::Expression filter_expr = cp::greater(cp::field_ref("a"), cp::literal(3));\n  // set filter for scanner : on-disk / push-down filtering.\n  // This step can be skipped if you are not reading from disk.\n  options->filter = filter_expr;\n  // empty projection\n  options->projection = cp::project({}, {});\n\n  // construct the scan node\n  std::cout << "Initialized Scanning Options" << std::endl;\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n  std::cout << "Scan node options created" << std::endl;\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n\n  // pipe the scan node into the filter node\n  // Need to set the filter in scan node options and filter node options.\n  // At scan node it is used for on-disk / push-down filtering.\n  // At filter node it is used for in-memory filtering.\n  ac::Declaration filter{\n      "filter", {std::move(scan)}, ac::FilterNodeOptions(std::move(filter_expr))};\n\n  return ExecutePlanAndCollectAsTable(std::move(filter));\n}\n\n// (Doc section: Filter Example)\n\n// (Doc section: Project Example)\n\n/// \\brief An example showing a project node\n///\n/// Scan-Project-Table\n/// This example shows how a Scan operation can be used to load the data\n/// into the execution plan, how a project operation can be applied on the\n/// data stream and how the output is collected into a table\nturbo::Status ScanProjectSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // projection\n  cp::Expression a_times_2 = cp::call("multiply", {cp::field_ref("a"), cp::literal(2)});\n  options->projection = cp::project({}, {});\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n  ac::Declaration project{\n      "project", {std::move(scan)}, ac::ProjectNodeOptions({a_times_2})};\n\n  return ExecutePlanAndCollectAsTable(std::move(project));\n}\n\n// (Doc section: Project Example)\n\n// This is a variation of ScanProjectSinkExample introducing how to use the\n// Declaration::Sequence function\nturbo::Status ScanProjectSequenceSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // projection\n  cp::Expression a_times_2 = cp::call("multiply", {cp::field_ref("a"), cp::literal(2)});\n  options->projection = cp::project({}, {});\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  // (Doc section: Project Sequence Example)\n  // Inputs do not have to be passed to the project node when using Sequence\n  ac::Declaration plan =\n      ac::Declaration::Sequence({{"scan", std::move(scan_node_options)},\n                                 {"project", ac::ProjectNodeOptions({a_times_2})}});\n  // (Doc section: Project Sequence Example)\n\n  return ExecutePlanAndCollectAsTable(std::move(plan));\n}\n\n// (Doc section: Scalar Aggregate Example)\n\n/// \\brief An example showing an aggregation node to aggregate an entire table\n///\n/// Source-Aggregation-Table\n/// This example shows how an aggregation operation can be applied on a\n/// execution plan resulting in a scalar output. The source node loads the\n/// data and the aggregation (counting unique types in column \'a\')\n/// is applied on this data. The output is collected into a table (that will\n/// have exactly one row)\nturbo::Status SourceScalarAggregateSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n  auto aggregate_options =\n      ac::AggregateNodeOptions{/*aggregates=*/{{"sum", nullptr, "a", "sum(a)"}}};\n  ac::Declaration aggregate{\n      "aggregate", {std::move(source)}, std::move(aggregate_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(aggregate));\n}\n// (Doc section: Scalar Aggregate Example)\n\n// (Doc section: Group Aggregate Example)\n\n/// \\brief An example showing an aggregation node to perform a group-by operation\n///\n/// Source-Aggregation-Table\n/// This example shows how an aggregation operation can be applied on a\n/// execution plan resulting in grouped output. The source node loads the\n/// data and the aggregation (counting unique types in column \'a\') is\n/// applied on this data. The output is collected into a table that will contain\n/// one row for each unique combination of group keys.\nturbo::Status SourceGroupAggregateSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n  auto options = std::make_shared<cp::CountOptions>(cp::CountOptions::ONLY_VALID);\n  auto aggregate_options =\n      ac::AggregateNodeOptions{/*aggregates=*/{{"hash_count", options, "a", "count(a)"}},\n                               /*keys=*/{"b"}};\n  ac::Declaration aggregate{\n      "aggregate", {std::move(source)}, std::move(aggregate_options)};\n\n  return ExecutePlanAndCollectAsTable(std::move(aggregate));\n}\n// (Doc section: Group Aggregate Example)\n\n// (Doc section: ConsumingSink Example)\n\n/// \\brief An example showing a consuming sink node\n///\n/// Source-Consuming-Sink\n/// This example shows how the data can be consumed within the execution plan\n/// by using a ConsumingSink node. There is no data output from this execution plan.\nturbo::Status SourceConsumingSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  ac::Declaration source{"source", std::move(source_node_options)};\n\n  std::atomic<uint32_t> batches_seen{0};\n  alkaid::Future<> finish = alkaid::Future<>::Make();\n  struct CustomSinkNodeConsumer : public ac::SinkNodeConsumer {\n    CustomSinkNodeConsumer(std::atomic<uint32_t>* batches_seen, alkaid::Future<> finish)\n        : batches_seen(batches_seen), finish(std::move(finish)) {}\n\n    turbo::Status Init(const std::shared_ptr<alkaid::Schema>& schema,\n                       ac::BackpressureControl* backpressure_control,\n                       ac::ExecPlan* plan) override {\n      // This will be called as the plan is started (before the first call to Consume)\n      // and provides the schema of the data coming into the node, controls for pausing /\n      // resuming input, and a pointer to the plan itself which can be used to access\n      // other utilities such as the thread indexer or async task scheduler.\n      return turbo::Status::OK();\n    }\n\n    turbo::Status Consume(cp::ExecBatch batch) override {\n      (*batches_seen)++;\n      return turbo::Status::OK();\n    }\n\n    alkaid::Future<> Finish() override {\n      // Here you can perform whatever (possibly async) cleanup is needed, e.g. closing\n      // output file handles and flushing remaining work\n      return alkaid::Future<>::MakeFinished();\n    }\n\n    std::atomic<uint32_t>* batches_seen;\n    alkaid::Future<> finish;\n  };\n  std::shared_ptr<CustomSinkNodeConsumer> consumer =\n      std::make_shared<CustomSinkNodeConsumer>(&batches_seen, finish);\n\n  ac::Declaration consuming_sink{"consuming_sink",\n                                 {std::move(source)},\n                                 ac::ConsumingSinkNodeOptions(std::move(consumer))};\n\n  // Since we are consuming the data within the plan there is no output and we simply\n  // run the plan to completion instead of collecting into a table.\n  TURBO_RETURN_NOT_OK(ac::DeclarationToStatus(std::move(consuming_sink)));\n\n  std::cout << "The consuming sink node saw " << batches_seen.load() << " batches"\n            << std::endl;\n  return turbo::Status::OK();\n}\n// (Doc section: ConsumingSink Example)\n\n// (Doc section: OrderBySink Example)\n\nturbo::Status ExecutePlanAndCollectAsTableWithCustomSink(\n    std::shared_ptr<ac::ExecPlan> plan, std::shared_ptr<alkaid::Schema> schema,\n    alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen) {\n  // translate sink_gen (async) to sink_reader (sync)\n  std::shared_ptr<alkaid::RecordBatchReader> sink_reader =\n      ac::MakeGeneratorReader(schema, std::move(sink_gen), alkaid::default_memory_pool());\n\n  // validate the ExecPlan\n  TURBO_RETURN_NOT_OK(plan->Validate());\n  std::cout << "ExecPlan created : " << plan->ToString() << std::endl;\n  // start the ExecPlan\n  plan->StartProducing();\n\n  // collect sink_reader into a Table\n  std::shared_ptr<alkaid::Table> response_table;\n\n  TURBO_MOVE_OR_RAISE(response_table,\n                        alkaid::Table::FromRecordBatchReader(sink_reader.get()));\n\n  std::cout << "Results : " << response_table->ToString() << std::endl;\n\n  // stop producing\n  plan->StopProducing();\n  // plan mark finished\n  auto future = plan->finished();\n  return future.status();\n}\n\n/// \\brief An example showing an order-by node\n///\n/// Source-OrderBy-Sink\n/// In this example, the data enters through the source node\n/// and the data is ordered in the sink node. The order can be\n/// ASCENDING or DESCENDING and it is configurable. The output\n/// is obtained as a table from the sink node.\nturbo::Status SourceOrderBySinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<ac::ExecPlan> plan,\n                        ac::ExecPlan::Make(*cp::threaded_exec_context()));\n\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeSortTestBasicBatches());\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n  TURBO_MOVE_OR_RAISE(ac::ExecNode * source,\n                        ac::MakeExecNode("source", plan.get(), {}, source_node_options));\n\n  TURBO_RETURN_NOT_OK(ac::MakeExecNode(\n      "order_by_sink", plan.get(), {source},\n      ac::OrderBySinkNodeOptions{\n          cp::SortOptions{{cp::SortKey{"a", cp::SortOrder::Descending}}}, &sink_gen}));\n\n  return ExecutePlanAndCollectAsTableWithCustomSink(plan, basic_data.schema, sink_gen);\n}\n\n// (Doc section: OrderBySink Example)\n\n// (Doc section: HashJoin Example)\n\n/// \\brief An example showing a hash join node\n///\n/// Source-HashJoin-Table\n/// This example shows how source node gets the data and how a self-join\n/// is applied on the data. The join options are configurable. The output\n/// is collected into a table.\nturbo::Status SourceHashJoinSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto input, MakeGroupableBatches());\n\n  ac::Declaration left{"source", ac::SourceNodeOptions{input.schema, input.gen()}};\n  ac::Declaration right{"source", ac::SourceNodeOptions{input.schema, input.gen()}};\n\n  ac::HashJoinNodeOptions join_opts{\n      ac::JoinType::INNER,\n      /*left_keys=*/{"str"},\n      /*right_keys=*/{"str"}, cp::literal(true), "l_", "r_"};\n\n  ac::Declaration hashjoin{\n      "hashjoin", {std::move(left), std::move(right)}, std::move(join_opts)};\n\n  return ExecutePlanAndCollectAsTable(std::move(hashjoin));\n}\n\n// (Doc section: HashJoin Example)\n\n// (Doc section: KSelect Example)\n\n/// \\brief An example showing a select-k node\n///\n/// Source-KSelect\n/// This example shows how K number of elements can be selected\n/// either from the top or bottom. The output node is a modified\n/// sink node where output can be obtained as a table.\nturbo::Status SourceKSelectExample() {\n  TURBO_MOVE_OR_RAISE(auto input, MakeGroupableBatches());\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<ac::ExecPlan> plan,\n                        ac::ExecPlan::Make(*cp::threaded_exec_context()));\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  TURBO_MOVE_OR_RAISE(\n      ac::ExecNode * source,\n      ac::MakeExecNode("source", plan.get(), {},\n                       ac::SourceNodeOptions{input.schema, input.gen()}));\n\n  cp::SelectKOptions options = cp::SelectKOptions::TopKDefault(/*k=*/2, {"i32"});\n\n  TURBO_RETURN_NOT_OK(ac::MakeExecNode("select_k_sink", plan.get(), {source},\n                                       ac::SelectKSinkNodeOptions{options, &sink_gen}));\n\n  auto schema = alkaid::schema(\n      {alkaid::field("i32", alkaid::int32()), alkaid::field("str", alkaid::utf8())});\n\n  return ExecutePlanAndCollectAsTableWithCustomSink(plan, schema, sink_gen);\n}\n\n// (Doc section: KSelect Example)\n\n// (Doc section: Write Example)\n\n/// \\brief An example showing a write node\n/// \\param file_path The destination to write to\n///\n/// Scan-Filter-Write\n/// This example shows how scan node can be used to load the data\n/// and after processing how it can be written to disk.\nturbo::Status ScanFilterWriteExample(const std::string& file_path) {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::dataset::Dataset> dataset, GetDataset());\n\n  auto options = std::make_shared<alkaid::dataset::ScanOptions>();\n  // empty projection\n  options->projection = cp::project({}, {});\n\n  auto scan_node_options = alkaid::dataset::ScanNodeOptions{dataset, options};\n\n  ac::Declaration scan{"scan", std::move(scan_node_options)};\n\n  alkaid::AsyncGenerator<std::optional<cp::ExecBatch>> sink_gen;\n\n  std::string root_path = "";\n  std::string uri = "file://" + file_path;\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<alkaid::fs::FileSystem> filesystem,\n                        alkaid::fs::FileSystemFromUri(uri, &root_path));\n\n  auto base_path = root_path + "/parquet_dataset";\n  // Uncomment the following line, if run repeatedly\n  // TURBO_RETURN_NOT_OK(filesystem->DeleteDirContents(base_path));\n  TURBO_RETURN_NOT_OK(filesystem->CreateDir(base_path));\n\n  // The partition schema determines which fields are part of the partitioning.\n  auto partition_schema = alkaid::schema({alkaid::field("a", alkaid::int32())});\n  // We\'ll use Hive-style partitioning,\n  // which creates directories with "key=value" pairs.\n\n  auto partitioning =\n      std::make_shared<alkaid::dataset::HivePartitioning>(partition_schema);\n  // We\'ll write Parquet files.\n  auto format = std::make_shared<alkaid::dataset::ParquetFileFormat>();\n\n  alkaid::dataset::FileSystemDatasetWriteOptions write_options;\n  write_options.file_write_options = format->DefaultWriteOptions();\n  write_options.filesystem = filesystem;\n  write_options.base_dir = base_path;\n  write_options.partitioning = partitioning;\n  write_options.basename_template = "part{i}.parquet";\n\n  alkaid::dataset::WriteNodeOptions write_node_options{write_options};\n\n  ac::Declaration write{"write", {std::move(scan)}, std::move(write_node_options)};\n\n  // Since the write node has no output we simply run the plan to completion and the\n  // data should be written\n  TURBO_RETURN_NOT_OK(ac::DeclarationToStatus(std::move(write)));\n\n  std::cout << "Dataset written to " << base_path << std::endl;\n  return turbo::Status::OK();\n}\n\n// (Doc section: Write Example)\n\n// (Doc section: Union Example)\n\n/// \\brief An example showing a union node\n///\n/// Source-Union-Table\n/// This example shows how a union operation can be applied on two\n/// data sources. The output is collected into a table.\nturbo::Status SourceUnionSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  ac::Declaration lhs{"source",\n                      ac::SourceNodeOptions{basic_data.schema, basic_data.gen()}};\n  lhs.label = "lhs";\n  ac::Declaration rhs{"source",\n                      ac::SourceNodeOptions{basic_data.schema, basic_data.gen()}};\n  rhs.label = "rhs";\n  ac::Declaration union_plan{\n      "union", {std::move(lhs), std::move(rhs)}, ac::ExecNodeOptions{}};\n\n  return ExecutePlanAndCollectAsTable(std::move(union_plan));\n}\n\n// (Doc section: Union Example)\n\n// (Doc section: Table Sink Example)\n\n/// \\brief An example showing a table sink node\n///\n/// TableSink Example\n/// This example shows how a table_sink can be used\n/// in an execution plan. This includes a source node\n/// receiving data as batches and the table sink node\n/// which emits the output as a table.\nturbo::Status TableSinkExample() {\n  TURBO_MOVE_OR_RAISE(std::shared_ptr<ac::ExecPlan> plan,\n                        ac::ExecPlan::Make(*cp::threaded_exec_context()));\n\n  TURBO_MOVE_OR_RAISE(auto basic_data, MakeBasicBatches());\n\n  auto source_node_options = ac::SourceNodeOptions{basic_data.schema, basic_data.gen()};\n\n  TURBO_MOVE_OR_RAISE(ac::ExecNode * source,\n                        ac::MakeExecNode("source", plan.get(), {}, source_node_options));\n\n  std::shared_ptr<alkaid::Table> output_table;\n  auto table_sink_options = ac::TableSinkNodeOptions{&output_table};\n\n  TURBO_RETURN_NOT_OK(\n      ac::MakeExecNode("table_sink", plan.get(), {source}, table_sink_options));\n  // validate the ExecPlan\n  TURBO_RETURN_NOT_OK(plan->Validate());\n  std::cout << "ExecPlan created : " << plan->ToString() << std::endl;\n  // start the ExecPlan\n  plan->StartProducing();\n\n  // Wait for the plan to finish\n  auto finished = plan->finished();\n  RETURN_NOT_OK(finished.status());\n  std::cout << "Results : " << output_table->ToString() << std::endl;\n  return turbo::Status::OK();\n}\n\n// (Doc section: Table Sink Example)\n\n// (Doc section: RecordBatchReaderSource Example)\n\n/// \\brief An example showing the usage of a RecordBatchReader as the data source.\n///\n/// RecordBatchReaderSourceSink Example\n/// This example shows how a record_batch_reader_source can be used\n/// in an execution plan. This includes the source node\n/// receiving data from a TableRecordBatchReader.\n\nturbo::Status RecordBatchReaderSourceSinkExample() {\n  TURBO_MOVE_OR_RAISE(auto table, GetTable());\n  std::shared_ptr<alkaid::RecordBatchReader> reader =\n      std::make_shared<alkaid::TableBatchReader>(table);\n  ac::Declaration reader_source{"record_batch_reader_source",\n                                ac::RecordBatchReaderSourceNodeOptions{reader}};\n  return ExecutePlanAndCollectAsTable(std::move(reader_source));\n}\n\n// (Doc section: RecordBatchReaderSource Example)\n\nenum ExampleMode {\n  SOURCE_SINK = 0,\n  TABLE_SOURCE_SINK = 1,\n  SCAN = 2,\n  FILTER = 3,\n  PROJECT = 4,\n  SCALAR_AGGREGATION = 5,\n  GROUP_AGGREGATION = 6,\n  CONSUMING_SINK = 7,\n  ORDER_BY_SINK = 8,\n  HASHJOIN = 9,\n  KSELECT = 10,\n  WRITE = 11,\n  UNION = 12,\n  TABLE_SOURCE_TABLE_SINK = 13,\n  RECORD_BATCH_READER_SOURCE = 14,\n  PROJECT_SEQUENCE = 15\n};\n\nint main(int argc, char** argv) {\n  if (argc < 3) {\n    // Fake success for CI purposes.\n    return EXIT_SUCCESS;\n  }\n\n  std::string base_save_path = argv[1];\n  int mode = std::atoi(argv[2]);\n  turbo::Status status;\n  // ensure alkaid::dataset node factories are in the registry\n  alkaid::dataset::internal::Initialize();\n  switch (mode) {\n    case SOURCE_SINK:\n      PrintBlock("Source Sink Example");\n      status = SourceSinkExample();\n      break;\n    case TABLE_SOURCE_SINK:\n      PrintBlock("Table Source Sink Example");\n      status = TableSourceSinkExample();\n      break;\n    case SCAN:\n      PrintBlock("Scan Example");\n      status = ScanSinkExample();\n      break;\n    case FILTER:\n      PrintBlock("Filter Example");\n      status = ScanFilterSinkExample();\n      break;\n    case PROJECT:\n      PrintBlock("Project Example");\n      status = ScanProjectSinkExample();\n      break;\n    case PROJECT_SEQUENCE:\n      PrintBlock("Project Example (using Declaration::Sequence)");\n      status = ScanProjectSequenceSinkExample();\n      break;\n    case GROUP_AGGREGATION:\n      PrintBlock("Aggregate Example");\n      status = SourceGroupAggregateSinkExample();\n      break;\n    case SCALAR_AGGREGATION:\n      PrintBlock("Aggregate Example");\n      status = SourceScalarAggregateSinkExample();\n      break;\n    case CONSUMING_SINK:\n      PrintBlock("Consuming-Sink Example");\n      status = SourceConsumingSinkExample();\n      break;\n    case ORDER_BY_SINK:\n      PrintBlock("OrderBy Example");\n      status = SourceOrderBySinkExample();\n      break;\n    case HASHJOIN:\n      PrintBlock("HashJoin Example");\n      status = SourceHashJoinSinkExample();\n      break;\n    case KSELECT:\n      PrintBlock("KSelect Example");\n      status = SourceKSelectExample();\n      break;\n    case WRITE:\n      PrintBlock("Write Example");\n      status = ScanFilterWriteExample(base_save_path);\n      break;\n    case UNION:\n      PrintBlock("Union Example");\n      status = SourceUnionSinkExample();\n      break;\n    case TABLE_SOURCE_TABLE_SINK:\n      PrintBlock("TableSink Example");\n      status = TableSinkExample();\n      break;\n    case RECORD_BATCH_READER_SOURCE:\n      PrintBlock("RecordBatchReaderSource Example");\n      status = RecordBatchReaderSourceSinkExample();\n      break;\n    default:\n      break;\n  }\n\n  if (status.ok()) {\n    return EXIT_SUCCESS;\n  } else {\n    std::cout << "Error occurred: " << status.message() << std::endl;\n    return EXIT_FAILURE;\n  }\n}\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>c});var a=t(96540);const s={},o=a.createContext(s);function i(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);