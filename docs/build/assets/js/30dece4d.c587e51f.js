"use strict";(self.webpackChunkkumo_website=self.webpackChunkkumo_website||[]).push([[28883],{23927:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var t=n(74848),o=n(28453);const r={},i="I/O Optimizations and the TpchBenchmark",a={id:"pollux/develop/tpch-benchmark",title:"I/O Optimizations and the TpchBenchmark",description:"Introduction",source:"@site/versioned_docs/version-1.1.1/pollux/develop/tpch-benchmark.mdx",sourceDirName:"pollux/develop",slug:"/pollux/develop/tpch-benchmark",permalink:"/docs/pollux/develop/tpch-benchmark",draft:!1,unlisted:!1,tags:[],version:"1.1.1",lastUpdatedBy:"Jeff lothar",lastUpdatedAt:1748143706e3,frontMatter:{}},l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Use Cases for Pollux",id:"use-cases-for-pollux",level:2},{value:"In-Process Multi-Threaded Executor Use Case",id:"in-process-multi-threaded-executor-use-case",level:2},{value:"Multiple Process Executor Use Case",id:"multiple-process-executor-use-case",level:2},{value:"Built-In TpchBenchmark",id:"built-in-tpchbenchmark",level:2},{value:"TpchBenchmark Tool Optimizations in Pollux",id:"tpchbenchmark-tool-optimizations-in-pollux",level:2},{value:"Top Optimization Recommendations",id:"top-optimization-recommendations",level:2},{value:"Optimizations for the TpchBenchmark (Single Process Use Case)",id:"optimizations-for-the-tpchbenchmark-single-process-use-case",level:2},{value:"<strong>num_drivers</strong>",id:"num_drivers",level:2},{value:"<strong>num_io_threads</strong>",id:"num_io_threads",level:2},{value:"<strong>cache_gb</strong>",id:"cache_gb",level:2},{value:"<strong>num_splits_per_file</strong>",id:"num_splits_per_file",level:2},{value:"Optimizations for All Workloads (Both Use Cases)",id:"optimizations-for-all-workloads-both-use-cases",level:2},{value:"<strong>max_coalesce_bytes</strong>",id:"max_coalesce_bytes",level:3},{value:"<strong>max_coalesce_distance_bytes</strong>",id:"max_coalesce_distance_bytes",level:3},{value:"Summary",id:"summary",level:2},{value:"Appendix A: TpchBenchmark Tool Help Output",id:"appendix-a-tpchbenchmark-tool-help-output",level:2}];function h(e){const s={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"io-optimizations-and-the-tpchbenchmark",children:"I/O Optimizations and the TpchBenchmark"})}),"\n",(0,t.jsx)(s.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(s.p,{children:"This document is the outcome from a cycle of benchmarking to determine the best\nI/O performance against AWS S3 Parquet data for TPCH. It is intended to describe\nthe tuning process recommendations and general suggestions for tuning the Pollux\nquery engine."}),"\n",(0,t.jsxs)(s.p,{children:["Benchmarking in Pollux is made easy with the optionally built TpchBenchmark\n(pollux_tpch_benchmark) executable. To build the benchmark executable\n(",(0,t.jsx)(s.em,{children:"_build/release/pollux/benchamrks/tpch/pollux_tpch_benchmark"}),"), use the\nfollowing command line to do the build with S3 support:"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-shell",children:'\n   $ make benchmarks-build EXTRA_CMAKE_FLAGS="-DPOLLUX_ENABLE_S3=ON"\n'})}),"\n",(0,t.jsx)(s.h2,{id:"use-cases-for-pollux",children:"Use Cases for Pollux"}),"\n",(0,t.jsx)(s.p,{children:"Pollux is a library so there are multiple ways to use it. This document will\ndescribe two models used by popular applications."}),"\n",(0,t.jsx)(s.h2,{id:"in-process-multi-threaded-executor-use-case",children:"In-Process Multi-Threaded Executor Use Case"}),"\n",(0,t.jsxs)(s.p,{children:["This use case is used by ",(0,t.jsx)(s.code,{children:"Presto <https://github.com/prestodb/presto>"}),"_ and, as\nit turns out, is the use case used by the ",(0,t.jsx)(s.em,{children:"Pollux TpchBenchmark Tool"})," below.\nThis use case uses a single multi-threaded process to perform execution of\nqueries in parallel. Each query is broken up into threads called ",(0,t.jsx)(s.strong,{children:"drivers"}),"\nvia a planning algorithm.  Each ",(0,t.jsx)(s.strong,{children:"driver"})," may also have a thread pool to\nperform I/O in a parallel manner. In the benchmarking tool both ",(0,t.jsx)(s.strong,{children:"driver"}),"\nthread count, and I/O thread count are exposed as command line configuration\noptions. In this use case, care must be taken to not create too many threads\nsince maximum number of threads is a product of ",(0,t.jsx)(s.strong,{children:"driver"})," threads and I/O\nthreads. In this use case, the application owns creating ",(0,t.jsx)(s.strong,{children:"drivers"})," and I/O\nThread pools for Pollux. In the case of the benchmark tool, the tool is\nresponsible for both ",(0,t.jsx)(s.strong,{children:"driver"})," threads and I/O threads."]}),"\n",(0,t.jsx)(s.h2,{id:"multiple-process-executor-use-case",children:"Multiple Process Executor Use Case"}),"\n",(0,t.jsxs)(s.p,{children:["This use case is used by Spark + ",(0,t.jsx)(s.code,{children:"Gluten <https://github.com/oap-project/gluten>"}),"_\nand it differs from the Presto use case where parallelism is concerned. Spark\nuses multiple processes where each process is a Gluten+Pollux query processor.\nSpark scales by using many Linux processes for query processing. In this case\nthis means that the ",(0,t.jsx)(s.strong,{children:"drivers"})," are outside of Pollux and Gluten and is defined\nby the Spark configuration and number of workers. Gluten takes on the role of\ncreating and exposing the I/O thread pool count to Spark as configuration and\nthen injecting the I/O thread pool into Pollux for parallel I/O."]}),"\n",(0,t.jsx)(s.h2,{id:"built-in-tpchbenchmark",children:"Built-In TpchBenchmark"}),"\n",(0,t.jsx)(s.p,{children:'This tool uses the "in-process" multi-threaded executor use case. This tool\nexposes quite a few benchmark options as command line options. It also\nexposes many Pollux internal options. This document will only cover a subset\nof the options and possible best-known values for them.'}),"\n",(0,t.jsx)(s.p,{children:"The setup used in experiments leading to this document was an AWS instance\nri6-8xlarge (32 vCPUs; 256GB RAM). The values (or formulas) below are based on\nthese experiments."}),"\n",(0,t.jsx)(s.h2,{id:"tpchbenchmark-tool-optimizations-in-pollux",children:"TpchBenchmark Tool Optimizations in Pollux"}),"\n",(0,t.jsx)(s.p,{children:"The tool exposes the following options (Note: When passing options for the tool\nuse a single dash not a double dash; i.e. -option and not --option):"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.em,{children:"num_drivers"})," - As described above this represent the number of drivers or\nexecutors used to process the TPC-H queries."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.em,{children:"num_io_threads"})," - This represents the number of I/O threads used per\n",(0,t.jsx)(s.strong,{children:"driver"})," for I/O."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.em,{children:"cache_gb"})," - How much memory is used for caching data locally in this\nprocess. Memory caching cannot be shared in the multiple process executor use\ncase but works well in the single process, multi-threaded use case."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.em,{children:"num_splits_per_file"})," - This is a row group optimization for the stored\ndataset for benchmarking."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"NOTE:"})," *There is a limitation on the implementation of the AWS SDK that\nwill cause failures (curl error 28) if the ",(0,t.jsx)(s.strong,{children:"driver"})," *threads times I/O threads\ngrow much beyond 350 threads. This only really effects the multi-threaded\n",(0,t.jsx)(s.strong,{children:"drivers"})," ",(0,t.jsx)(s.em,{children:"use case like the benchmark tool. It is only known to be an issue\nwhen running against AWS S3. However, the error is coming from the libcurl\nlibrary so it is possible other Cloud storage APIs could also be affected."})]}),"\n",(0,t.jsx)(s.p,{children:"Pollux exposes other options used for tuning that are of interest:"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.em,{children:"max_coalesce_bytes"})," - Size of coalesced data, has small improvements as size\ngrows."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.em,{children:"max_coalesce_distance_bytes"})," - Maximum gap bytes between data that can\ncoalesced. Larger may mean more fetched data but at greater bytes/sec."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"top-optimization-recommendations",children:"Top Optimization Recommendations"}),"\n",(0,t.jsx)(s.p,{children:'.. csv-table:: Starting Point for Tuning\n:header: "Option Name", "Single Process", "Multi-Process"\n:widths: auto'}),"\n",(0,t.jsxs)(s.p,{children:['"num_drivers",',(0,t.jsx)(s.code,{children:"max(20, vCPUs<super>*</super> X 3 / 4)"}),',"NA"\n"num_io_threads", ',(0,t.jsx)(s.code,{children:"max(16, vCPUs<super>*</super> X 3 / 8)"}),', "vCPUs*"\n"cache_gb", "50% System RAM", "NA (default = 0)"\n"num_splits_per_file", "Row Group Size of Data", "Row Group Size of Data"\n"max_coalesced_bytes", "Minimum of 90MB", "Minimum of 90MB"\n"max_coalesced_distance_bytes", "Workload dependent**", "Workload dependent**"\n"parquet_prefetch_rowgroups", "Best is 1", "Best is 1"\n"split_preload_per_driver", "Best is 2", "Best is 2"\n"cache_prefetch_min_pct", "Best is 80", "Best is 80"']}),"\n",(0,t.jsx)(s.p,{children:"*  vCPUs = (cores * hyper-threads)"}),"\n",(0,t.jsx)(s.p,{children:"** Wide tables and few columns retrieved per row can lead to many I/O\nrequests, suggest increasing this value based on testing and the need to\nreduce small I/O requests."}),"\n",(0,t.jsx)(s.h2,{id:"optimizations-for-the-tpchbenchmark-single-process-use-case",children:"Optimizations for the TpchBenchmark (Single Process Use Case)"}),"\n",(0,t.jsx)(s.h2,{id:"num_drivers",children:(0,t.jsx)(s.strong,{children:"num_drivers"})}),"\n",(0,t.jsx)(s.p,{children:"This configuration option describes the number of resources available to\nprocess query plan tasks. This can greatly improve performance of CPU bound\nworkloads. The recommendation in the table above seems to be optimal for\nTPCH-like workloads."}),"\n",(0,t.jsx)(s.h2,{id:"num_io_threads",children:(0,t.jsx)(s.strong,{children:"num_io_threads"})}),"\n",(0,t.jsx)(s.p,{children:"This configuration option describes the number of threads available per driver\nto retrieve data from the network source. If the workload is I/O bound, then\nincreasing this number is beneficial if the data is fewer requests of larger\nchunks as opposed to many smaller requests."}),"\n",(0,t.jsx)(s.h2,{id:"cache_gb",children:(0,t.jsx)(s.strong,{children:"cache_gb"})}),"\n",(0,t.jsxs)(s.p,{children:["This configuration option is useful for workloads that read the same data\nseveral times per query but only applies to the single process use case.\n",(0,t.jsx)(s.em,{children:"NOTE: There is a SSD Caching option in Pollux but it to is ONLY useful in\nthe single process use case."})]}),"\n",(0,t.jsx)(s.h2,{id:"num_splits_per_file",children:(0,t.jsx)(s.strong,{children:"num_splits_per_file"})}),"\n",(0,t.jsx)(s.p,{children:"This configuration option is best when the data set count of row groups\nmatches this value. The affect in overall performance appears based on\ntesting to be small, however."}),"\n",(0,t.jsx)(s.h2,{id:"optimizations-for-all-workloads-both-use-cases",children:"Optimizations for All Workloads (Both Use Cases)"}),"\n",(0,t.jsx)(s.h3,{id:"max_coalesce_bytes",children:(0,t.jsx)(s.strong,{children:"max_coalesce_bytes"})}),"\n",(0,t.jsx)(s.p,{children:"This configuration option is the maximum bytes coalesced into a single request\nto the data source. This was tested from the default 128MB to 2GB, and the\noverall improvement was small as size increased. Capturing request data did\nshow larger and fewer requests but not enough to vastly improve I/O performance."}),"\n",(0,t.jsx)(s.h3,{id:"max_coalesce_distance_bytes",children:(0,t.jsx)(s.strong,{children:"max_coalesce_distance_bytes"})}),"\n",(0,t.jsxs)(s.p,{children:["This configuration option is the maximum byte distance between needed data in\nthe same file at the data source that can be coalesced. Increasing this value\nwould theoretically reduce the number of requests and increase each request\nsize. However, if made too large the query will return too many un-needed bytes\nand could decrease I/O performance. This plus ",(0,t.jsx)(s.strong,{children:"max_coalesce_bytes"})," should be\nfine-tuned for the workload being run."]}),"\n",(0,t.jsx)(s.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(s.p,{children:"If a use of Pollux matches the use case of the TcphBenchmark then it is a good\ntool to test, I/O and driver performance for specific TCP-H queries. This would\nbenefit execution of specific production workloads that are like the chosen\nqueries. If in multi-process use case, like Spark/Gluten/Pollux configuration,\nthe recommendation is to oversubscribe I/O threads between 2X and 3X vCPUs and\ntune the 2 coalesce configurations exposed."}),"\n",(0,t.jsx)(s.h2,{id:"appendix-a-tpchbenchmark-tool-help-output",children:"Appendix A: TpchBenchmark Tool Help Output"}),"\n",(0,t.jsx)(s.p,{children:"From the repository root, use the following command line to see all the\navailable flags in the TpchBenchmark tool."}),"\n",(0,t.jsx)(s.p,{children:".. code:: shell"}),"\n",(0,t.jsx)(s.p,{children:"$ ./_build/release/pollux/benchmarks/tpch/pollux_tpch_benchmark -helpon=TpchBenchmark"})]})}function d(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},28453:(e,s,n)=>{n.d(s,{R:()=>i,x:()=>a});var t=n(96540);const o={},r=t.createContext(o);function i(e){const s=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),t.createElement(r.Provider,{value:s},e.children)}}}]);